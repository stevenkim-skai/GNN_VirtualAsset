{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3_Reconstruction_Error.ipynb\n",
        "# 목적: 검증 노드의 재구성 오차 기반 이상치 탐지 수행\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# PyG 필요\n",
        "USE_PYG = True\n",
        "try:\n",
        "    from torch_geometric.data import Data\n",
        "    from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "except Exception as e:\n",
        "    print('torch_geometric not available:', e)\n",
        "    USE_PYG = False\n",
        "\n",
        "if not USE_PYG:\n",
        "    raise RuntimeError('torch_geometric 필요: pip install torch-geometric')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded G: nodes=7958, edges=14128\n",
            "Loaded weights for GCN_AE from models\\GCN_AE.pth\n",
            "Loaded weights for SAGE_AE from models\\SAGE_AE.pth\n",
            "Loaded weights for GAT_AE from models\\GAT_AE.pth\n",
            "Loaded weights for PaperGAT_AE from models\\PaperGAT_AE.pth\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 파일 경로\n",
        "GRAPH_PATH = 'G_graph.gpickle'\n",
        "MODEL_DIRS = ['models', '.']  # 모델 파일을 찾을 경로 목록\n",
        "MODEL_NAMES = ['GCN_AE', 'SAGE_AE', 'GAT_AE', 'PaperGAT_AE']\n",
        "\n",
        "# 1) 그래프 불러오기\n",
        "try:\n",
        "    try:\n",
        "        G = nx.read_gpickle(GRAPH_PATH)\n",
        "    except AttributeError:\n",
        "        with open(GRAPH_PATH, 'rb') as f:\n",
        "            G = pickle.load(f)\n",
        "    print(f'Loaded G: nodes={G.number_of_nodes()}, edges={G.number_of_edges()}')\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f'Failed to load {GRAPH_PATH}: {e}')\n",
        "\n",
        "# 2) PyG Data 구성 (노드 피처: centralitypagerank, uniqedgesIn, cycles, dayvaloutlier)\n",
        "nodes = list(G.nodes())\n",
        "idx_map = {n: i for i, n in enumerate(nodes)}\n",
        "\n",
        "X_list = []\n",
        "for n in nodes:\n",
        "    d = G.nodes[n]\n",
        "    pr = float(d.get('centralitypagerank', 0.0))\n",
        "    uniqin = float(d.get('uniqedgesIn', 0))\n",
        "    cycles = float(d.get('cycles', 0))\n",
        "    dayout = 1.0 if bool(d.get('dayvaloutlier', False)) else 0.0\n",
        "    X_list.append([pr, uniqin, cycles, dayout])\n",
        "\n",
        "X = torch.tensor(np.array(X_list), dtype=torch.float)\n",
        "\n",
        "edge_src, edge_dst, edge_attr = [], [], []\n",
        "for u, v, edata in G.edges(data=True):\n",
        "    if u in idx_map and v in idx_map:\n",
        "        edge_src.append(idx_map[u]); edge_dst.append(idx_map[v])\n",
        "        edge_attr.append(float(edata.get('netValue', 0.0)))\n",
        "\n",
        "edge_index = torch.tensor([edge_src, edge_dst], dtype=torch.long)\n",
        "edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1) if len(edge_attr)>0 else None\n",
        "\n",
        "data = Data(x=X, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# 노드 분할이 그래프에 저장되어 있으면 사용, 없으면 랜덤 8:2 (seed 고정)\n",
        "if hasattr(data, 'train_mask') and hasattr(data, 'val_mask'):\n",
        "    train_mask = data.train_mask\n",
        "    val_mask = data.val_mask\n",
        "else:\n",
        "    num_nodes = X.shape[0]\n",
        "    idxs = np.arange(num_nodes)\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(idxs)\n",
        "    train_n = int(num_nodes*0.8)\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool); val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    train_mask[idxs[:train_n]] = True; val_mask[idxs[train_n:]] = True\n",
        "\n",
        "# 3) 모델 클래스 정의 (2_GNN과 동일한 구조)\n",
        "class GCN_AE(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, lat_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_ch, hid_ch)\n",
        "        self.conv2 = GCNConv(hid_ch, lat_ch)\n",
        "        self.decoder = nn.Linear(lat_ch, in_ch)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index); x = torch.relu(x)\n",
        "        z = self.conv2(x, edge_index)\n",
        "        recon = self.decoder(z)\n",
        "        return z, recon\n",
        "\n",
        "class SAGE_AE(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, lat_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_ch, hid_ch)\n",
        "        self.conv2 = SAGEConv(hid_ch, lat_ch)\n",
        "        self.decoder = nn.Linear(lat_ch, in_ch)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index); x = torch.relu(x)\n",
        "        z = self.conv2(x, edge_index)\n",
        "        recon = self.decoder(z)\n",
        "        return z, recon\n",
        "\n",
        "class GAT_AE(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, lat_ch, heads=4, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_ch, hid_ch)\n",
        "        self.gat1 = GATConv(hid_ch, hid_ch//heads, heads=heads, dropout=dropout)\n",
        "        self.gat2 = GATConv((hid_ch//heads)*heads, lat_ch, heads=1, dropout=dropout)\n",
        "        self.decoder = nn.Linear(lat_ch, in_ch)\n",
        "        self.act = nn.ELU(); self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.proj(x); x = self.act(x); x = self.drop(x)\n",
        "        x = self.gat1(x, edge_index); x = self.act(x)\n",
        "        z = self.gat2(x, edge_index)\n",
        "        recon = self.decoder(z)\n",
        "        return z, recon\n",
        "\n",
        "class PaperGAT_AE(nn.Module):\n",
        "    def __init__(self, in_ch, embed_dim=64, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(in_ch, embed_dim)\n",
        "        self.gat_e1 = GATConv(embed_dim, 256//8, heads=8, dropout=dropout)\n",
        "        self.gat_e2 = GATConv(256, 32, heads=1, dropout=dropout)\n",
        "        self.gat_d1 = GATConv(32, 64, heads=1, dropout=dropout)\n",
        "        self.output_proj = nn.Linear(64, in_ch)\n",
        "        self.act = nn.ELU(); self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.input_proj(x); x = self.act(x); x = self.drop(x)\n",
        "        x = self.gat_e1(x, edge_index); x = self.act(x); x = self.drop(x)\n",
        "        x = self.gat_e2(x, edge_index)\n",
        "        z = x\n",
        "        x = self.act(x); x = self.drop(x)\n",
        "        x = self.gat_d1(x, edge_index); x = self.act(x)\n",
        "        recon = self.output_proj(x)\n",
        "        return z, recon\n",
        "\n",
        "# 4) 모델 인스턴스화 및 체크포인트 로드 (있으면)\n",
        "in_dim = data.x.shape[1]\n",
        "hidden_dim = 128\n",
        "latent_dim = 64\n",
        "\n",
        "def try_load_model(name, model):\n",
        "    # 후보 경로 목록\n",
        "    candidates = []\n",
        "    for d in MODEL_DIRS:\n",
        "        candidates.append(os.path.join(d, f'{name}.pt'))\n",
        "        candidates.append(os.path.join(d, f'{name}.pth'))\n",
        "    # 또한 전체 딕셔너리 파일 가능성\n",
        "    for path in candidates:\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                model.load_state_dict(torch.load(path, map_location='cpu'))\n",
        "                print(f'Loaded weights for {name} from {path}')\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f'Failed to load {path}: {e}')\n",
        "    print(f'No checkpoint found for {name} (searched: {candidates})')\n",
        "    return False\n",
        "\n",
        "model_instances = {\n",
        "    'GCN_AE': GCN_AE(in_dim, 128, latent_dim),\n",
        "    'SAGE_AE': SAGE_AE(in_dim, 128, latent_dim),\n",
        "    'GAT_AE': GAT_AE(in_dim, 128, latent_dim, heads=4, dropout=0.3),\n",
        "    'PaperGAT_AE': PaperGAT_AE(in_dim, embed_dim=64, dropout=0.3)\n",
        "}\n",
        "\n",
        "loaded_models = {}\n",
        "for name, mdl in model_instances.items():\n",
        "    ok = try_load_model(name, mdl)\n",
        "    loaded_models[name] = {'model': mdl, 'loaded': ok}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing model: GCN_AE (loaded=True)\n",
            "  val_count=1592 mean=1778398.375000 std=16291265.000000 anomalies(z>2)=1 (z>3)=1\n",
            "  saved -> recon_errors_GCN_AE.csv\n",
            "Processing model: SAGE_AE (loaded=True)\n",
            "  val_count=1592 mean=59957.285156 std=40967.734375 anomalies(z>2)=156 (z>3)=4\n",
            "  saved -> recon_errors_SAGE_AE.csv\n",
            "Processing model: GAT_AE (loaded=True)\n",
            "  val_count=1592 mean=3018049.250000 std=1117918.625000 anomalies(z>2)=0 (z>3)=0\n",
            "  saved -> recon_errors_GAT_AE.csv\n",
            "Processing model: PaperGAT_AE (loaded=True)\n",
            "  val_count=1592 mean=4197445.500000 std=2067450.250000 anomalies(z>2)=0 (z>3)=0\n",
            "  saved -> recon_errors_PaperGAT_AE.csv\n",
            "\n",
            "Summary:\n",
            "         model  val_count          mean           std  anomaly_z2  anomaly_z3  \\\n",
            "0       GCN_AE       1592  1.778398e+06  1.629126e+07           1           1   \n",
            "1      SAGE_AE       1592  5.995729e+04  4.096773e+04         156           4   \n",
            "2       GAT_AE       1592  3.018049e+06  1.117919e+06           0           0   \n",
            "3  PaperGAT_AE       1592  4.197446e+06  2.067450e+06           0           0   \n",
            "\n",
            "                            csv  \n",
            "0       recon_errors_GCN_AE.csv  \n",
            "1      recon_errors_SAGE_AE.csv  \n",
            "2       recon_errors_GAT_AE.csv  \n",
            "3  recon_errors_PaperGAT_AE.csv  \n",
            "\n",
            "Saved summary -> recon_errors_summary.csv\n",
            "\n",
            "Top anomalies (z>3) for GCN_AE (showing up to 20):\n",
            "      node_index                                     address  recon_error  \\\n",
            "219        1191  0xf80a39a8bb160b82ace500e951e4ae61b0eb616e  651073700.0   \n",
            "\n",
            "       zscore  \n",
            "219  39.85543  \n",
            "\n",
            "Top anomalies (z>3) for SAGE_AE (showing up to 20):\n",
            "       node_index                                     address  recon_error  \\\n",
            "1558        7797  0x99a7f147a106fc8d0f650175e095a31c198fd94f    355650.72   \n",
            "1535        7675  0xad3bd66b13848352346aec626ef1100a8ff05b22    355644.97   \n",
            "651         3310  0xf251c6769912461607bff0cd9998b50b5fba901a    224281.03   \n",
            "196         1066  0x2c62f232dfa0ed525ee489d0ef3fc0e43516e8ce    224281.02   \n",
            "\n",
            "        zscore  \n",
            "1558  7.217715  \n",
            "1535  7.217575  \n",
            "651   4.011053  \n",
            "196   4.011053  \n",
            "\n",
            "Top anomalies (z>3) for GAT_AE (showing up to 20):\n",
            " Empty DataFrame\n",
            "Columns: [node_index, address, recon_error, zscore]\n",
            "Index: []\n",
            "\n",
            "Top anomalies (z>3) for PaperGAT_AE (showing up to 20):\n",
            " Empty DataFrame\n",
            "Columns: [node_index, address, recon_error, zscore]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5) 재구성 오차 계산 및 z-score 기반 이상치 탐지\n",
        "from math import isfinite\n",
        "\n",
        "def compute_recon_errors(mdl, data, device='cpu'):\n",
        "    mdl.to(device); mdl.eval()\n",
        "    x = data.x.to(device); edge_index = data.edge_index.to(device)\n",
        "    with torch.no_grad():\n",
        "        z, recon = mdl(x, edge_index)\n",
        "    # per-node MSE across features\n",
        "    se = (recon - x).pow(2).mean(dim=1).cpu().numpy()\n",
        "    return se\n",
        "\n",
        "results_list = []\n",
        "for name, info in loaded_models.items():\n",
        "    mdl = info['model']\n",
        "    print(f'Processing model: {name} (loaded={info[\"loaded\"]})')\n",
        "    try:\n",
        "        errors = compute_recon_errors(mdl, data, device='cpu')\n",
        "    except Exception as e:\n",
        "        print(f'Failed to compute recon for {name}: {e}')\n",
        "        continue\n",
        "    # use validation nodes only\n",
        "    val_idxs = np.where(val_mask.numpy())[0]\n",
        "    val_errs = errors[val_idxs]\n",
        "    mean = val_errs.mean(); std = val_errs.std(ddof=0)\n",
        "    # avoid zero std\n",
        "    if std == 0:\n",
        "        zscores = np.zeros_like(val_errs)\n",
        "    else:\n",
        "        zscores = (val_errs - mean) / std\n",
        "    # flags\n",
        "    flag_z2 = zscores > 2\n",
        "    flag_z3 = zscores > 3\n",
        "    # compose dataframe for this model\n",
        "    dfm = pd.DataFrame({\n",
        "        'node_index': val_idxs,\n",
        "        'address': [nodes[i] for i in val_idxs],\n",
        "        'recon_error': val_errs,\n",
        "        'zscore': zscores,\n",
        "        'anomaly_z2': flag_z2,\n",
        "        'anomaly_z3': flag_z3\n",
        "    })\n",
        "    # try attach any known labels stored in node attributes\n",
        "    possible_label_keys = ['label','is_exchange','exchange','tag','type']\n",
        "    for k in possible_label_keys:\n",
        "        if any(k in G.nodes[n] for n in nodes):\n",
        "            dfm[k] = [G.nodes[n].get(k) for n in dfm['address']]\n",
        "    # summary counts\n",
        "    cnt_z2 = int(dfm['anomaly_z2'].sum())\n",
        "    cnt_z3 = int(dfm['anomaly_z3'].sum())\n",
        "    print(f'  val_count={len(val_idxs)} mean={mean:.6f} std={std:.6f} anomalies(z>2)={cnt_z2} (z>3)={cnt_z3}')\n",
        "    # save individual model results\n",
        "    out_csv = f'recon_errors_{name}.csv'\n",
        "    dfm.to_csv(out_csv, index=False)\n",
        "    print(f'  saved -> {out_csv}')\n",
        "    results_list.append({'model': name, 'val_count': int(len(val_idxs)), 'mean': float(mean), 'std': float(std), 'anomaly_z2': cnt_z2, 'anomaly_z3': cnt_z3, 'csv': out_csv})\n",
        "\n",
        "# 6) 통합 요약 저장\n",
        "df_summary = pd.DataFrame(results_list)\n",
        "df_summary.to_csv('recon_errors_summary.csv', index=False)\n",
        "print('\\nSummary:')\n",
        "print(df_summary)\n",
        "print('\\nSaved summary -> recon_errors_summary.csv')\n",
        "\n",
        "# 7) 상위 이상치(예: z>3) 샘플 출력\n",
        "for r in results_list:\n",
        "    dfm = pd.read_csv(r['csv'])\n",
        "    high = dfm.loc[dfm['anomaly_z3']].sort_values('zscore', ascending=False).head(20)\n",
        "    print(f\"\\nTop anomalies (z>3) for {r['model']} (showing up to 20):\\n\", high[['node_index','address','recon_error','zscore']])\n",
        "\n",
        "# 끝: 생성된 파일들 -> recon_errors_*.csv, recon_errors_summary.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
