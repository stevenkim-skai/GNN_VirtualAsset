{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Node2Vec(64d) + GraphSAGE 오토인코더(256->32->64) 학습 후\n",
    "재구성오차 z-score 정규화, 상위 5% 이상치 탐지\n",
    "필요: torch, torch_geometric, pandas, networkx, numpy\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import Node2Vec, SAGEConv\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 경로/환경 설정\n",
    "NODE_FEAT_CSV = \"node_features.csv\"\n",
    "GRAPH_PKL = \"G_base_multidigraph.pkl\"   # 이전 단계 저장 파일\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장치: cpu, 노드 수: 7958, 엣지 수: 25601\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) 노드/그래프 로딩\n",
    "node_df = pd.read_csv(NODE_FEAT_CSV)\n",
    "addresses = node_df['address'].astype(str).tolist()\n",
    "addr2idx = {a: i for i, a in enumerate(addresses)}\n",
    "\n",
    "if not os.path.exists(GRAPH_PKL):\n",
    "    raise FileNotFoundError(f\"{GRAPH_PKL} 파일이 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "with open(GRAPH_PKL, \"rb\") as f:\n",
    "    G_nx = pickle.load(f)  # MultiDiGraph\n",
    "\n",
    "# edge_index (방향 그래프). 필요 시 무방향으로 만들려면 아래 주석 해제\n",
    "edges = []\n",
    "for u, v, _k in G_nx.edges(keys=True):\n",
    "    if u in addr2idx and v in addr2idx:\n",
    "        edges.append([addr2idx[u], addr2idx[v]])\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# # (선택) 양방향 추가: GNN 안정화에 도움이 될 수 있음\n",
    "# edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "num_nodes = len(addresses)\n",
    "data = Data(edge_index=edge_index, num_nodes=num_nodes).to(DEVICE)\n",
    "\n",
    "print(f\"장치: {DEVICE}, 노드 수: {num_nodes}, 엣지 수: {edge_index.size(1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'Node2Vec' requires either the 'pyg-lib' or 'torch-cluster' package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 1) Node2Vec 임베딩(64차원) 생성\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 요청 파라미터 매핑:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#   embedding_dim=64, walk_length=30, context_size=10(window),\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#   walks_per_node=200(num_walk), p=1, q=1, workers=4\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# (min_count, batch_words는 gensim 전용 → PyG에는 해당 없음)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m n2v \u001b[38;5;241m=\u001b[39m Node2Vec(\n\u001b[0;32m      8\u001b[0m     data\u001b[38;5;241m.\u001b[39medge_index,\n\u001b[0;32m      9\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     10\u001b[0m     walk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     11\u001b[0m     context_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     12\u001b[0m     walks_per_node\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m     13\u001b[0m     p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     14\u001b[0m     q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     15\u001b[0m     num_negative_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     16\u001b[0m     sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     19\u001b[0m n2v_loader \u001b[38;5;241m=\u001b[39m n2v\u001b[38;5;241m.\u001b[39mloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     20\u001b[0m n2v_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSparseAdam(\u001b[38;5;28mlist\u001b[39m(n2v\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\models\\node2vec.py:67\u001b[0m, in \u001b[0;36mNode2Vec.__init__\u001b[1;34m(self, edge_index, embedding_dim, walk_length, context_size, walks_per_node, p, q, num_negative_samples, num_nodes, sparse)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires either the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-cluster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m package\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m                           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-cluster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m package\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: 'Node2Vec' requires either the 'pyg-lib' or 'torch-cluster' package"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Node2Vec 임베딩(64차원) 생성\n",
    "# 요청 파라미터 매핑:\n",
    "#   embedding_dim=64, walk_length=30, context_size=10(window),\n",
    "#   walks_per_node=200(num_walk), p=1, q=1, workers=4\n",
    "# (min_count, batch_words는 gensim 전용 → PyG에는 해당 없음)\n",
    "n2v = Node2Vec(\n",
    "    data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=30,\n",
    "    context_size=10,\n",
    "    walks_per_node=200,\n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    num_negative_samples=1,\n",
    "    sparse=True\n",
    ").to(DEVICE)\n",
    "\n",
    "n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "n2v_optimizer = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "def train_node2vec(epochs=5):\n",
    "    n2v.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.0\n",
    "        for pos_rw, neg_rw in n2v_loader:\n",
    "            n2v_optimizer.zero_grad()\n",
    "            loss = n2v.loss(pos_rw.to(DEVICE), neg_rw.to(DEVICE))\n",
    "            loss.backward()\n",
    "            n2v_optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[Node2Vec] epoch {epoch:03d} | loss {total_loss/len(n2v_loader):.4f}\")\n",
    "\n",
    "train_node2vec(epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    x_init = n2v.embedding.weight.clone().detach()  # (N, 64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) GraphSAGE 오토인코더\n",
    "# - 64 -> 256 -> 32 -> 64\n",
    "# - 활성화 ELU, 드롭아웃 0.3\n",
    "# - 손실 MSE (입력 x_init 대비 복원 x_hat)\n",
    "\n",
    "class SAGEAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3, aggr=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.sage1 = SAGEConv(in_channels=in_dim, out_channels=256, aggr=aggr)\n",
    "        self.sage2 = SAGEConv(in_channels=256, out_channels=32, aggr=aggr)\n",
    "        self.sage3 = SAGEConv(in_channels=32, out_channels=64, aggr=aggr)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.sage2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.sage3(x, edge_index)  # 복원 64d (보통 마지막은 활성 미적용)\n",
    "        return x\n",
    "\n",
    "model = SAGEAutoEncoder(in_dim=64, dropout=0.3, aggr=\"mean\").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) 학습 (1000 epoch, MSE 재구성오차 최소화)\n",
    "x_in = x_init.to(DEVICE)\n",
    "\n",
    "def train_sage_ae(epochs=1000):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        optimizer.zero_grad()\n",
    "        x_hat = model(x_in, data.edge_index)\n",
    "        loss = F.mse_loss(x_hat, x_in)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 50 == 0 or epoch == 1:\n",
    "            print(f\"[SAGE-AE] epoch {epoch:04d} | recon MSE {loss.item():.6f}\")\n",
    "\n",
    "train_sage_ae(epochs=1000)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) 재구성오차 → z-score → 상위 5% 이상치\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_recon = model(x_in, data.edge_index)\n",
    "\n",
    "recon_err = torch.mean((x_recon - x_in)**2, dim=1).detach().cpu().numpy()\n",
    "mu = recon_err.mean()\n",
    "sigma = recon_err.std(ddof=1) if recon_err.size > 1 else 1e-8\n",
    "z = (recon_err - mu) / (sigma if sigma > 0 else 1e-8)\n",
    "\n",
    "z_cut = np.percentile(z, 95.0)\n",
    "anom = (z > z_cut).astype(int)\n",
    "\n",
    "print(f\"상위 5% z-score 임계값: {z_cut:.4f}\")\n",
    "print(f\"이상치 노드 수: {anom.sum()} / {len(anom)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) 결과 저장\n",
    "out = pd.DataFrame({\n",
    "    \"address\": addresses,\n",
    "    \"recon_mse\": recon_err,\n",
    "    \"z_score\": z,\n",
    "    \"is_anomaly_top5pct\": anom\n",
    "})\n",
    "out.sort_values(\"z_score\", ascending=False).to_csv(\"sage_ae_anomalies.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "torch.save(model.state_dict(), \"sage_autoencoder.pt\")\n",
    "np.save(\"node2vec_embeddings_sage.npy\", x_init.detach().cpu().numpy())\n",
    "\n",
    "print(\"✅ 완료: sage_ae_anomalies.csv / sage_autoencoder.pt / node2vec_embeddings_sage.npy 생성\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
