{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyg-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Node2Vec(64d) + GraphSAGE 오토인코더(256->32->64) 학습 후\n",
    "재구성오차 z-score 정규화, 상위 5% 이상치 탐지\n",
    "필요: torch, torch_geometric, pandas, networkx, numpy\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import Node2Vec, SAGEConv\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 경로/환경 설정\n",
    "NODE_FEAT_CSV = \"node_features.csv\"\n",
    "GRAPH_PKL = \"G_base_multidigraph.pkl\"   # 이전 단계 저장 파일\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장치: cpu, 노드 수: 7958, 엣지 수: 25601\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) 노드/그래프 로딩\n",
    "node_df = pd.read_csv(NODE_FEAT_CSV)\n",
    "addresses = node_df['address'].astype(str).tolist()\n",
    "addr2idx = {a: i for i, a in enumerate(addresses)}\n",
    "\n",
    "if not os.path.exists(GRAPH_PKL):\n",
    "    raise FileNotFoundError(f\"{GRAPH_PKL} 파일이 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "with open(GRAPH_PKL, \"rb\") as f:\n",
    "    G_nx = pickle.load(f)  # MultiDiGraph\n",
    "\n",
    "# edge_index (방향 그래프). 필요 시 무방향으로 만들려면 아래 주석 해제\n",
    "edges = []\n",
    "for u, v, _k in G_nx.edges(keys=True):\n",
    "    if u in addr2idx and v in addr2idx:\n",
    "        edges.append([addr2idx[u], addr2idx[v]])\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# # (선택) 양방향 추가: GNN 안정화에 도움이 될 수 있음\n",
    "# edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "num_nodes = len(addresses)\n",
    "data = Data(edge_index=edge_index, num_nodes=num_nodes).to(DEVICE)\n",
    "\n",
    "print(f\"장치: {DEVICE}, 노드 수: {num_nodes}, 엣지 수: {edge_index.size(1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Node2Vec 임베딩(64차원) 생성\n",
    "# 요청 파라미터 매핑:\n",
    "#   embedding_dim=64, walk_length=30, context_size=10(window),\n",
    "#   walks_per_node=200(num_walk), p=1, q=1, workers=4\n",
    "# (min_count, batch_words는 gensim 전용 → PyG에는 해당 없음)\n",
    "n2v = Node2Vec(\n",
    "    data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=30,\n",
    "    context_size=10,\n",
    "    walks_per_node=200,\n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    num_negative_samples=1,\n",
    "    sparse=True\n",
    ").to(DEVICE)\n",
    "\n",
    "n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=0)\n",
    "n2v_optimizer = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "def train_node2vec(epochs=5):\n",
    "    n2v.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.0\n",
    "        for pos_rw, neg_rw in n2v_loader:\n",
    "            n2v_optimizer.zero_grad()\n",
    "            loss = n2v.loss(pos_rw.to(DEVICE), neg_rw.to(DEVICE))\n",
    "            loss.backward()\n",
    "            n2v_optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[Node2Vec] epoch {epoch:03d} | loss {total_loss/len(n2v_loader):.4f}\")\n",
    "\n",
    "train_node2vec(epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    x_init = n2v.embedding.weight.clone().detach()  # (N, 64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) GraphSAGE 오토인코더\n",
    "# - 64 -> 256 -> 32 -> 64\n",
    "# - 활성화 ELU, 드롭아웃 0.3\n",
    "# - 손실 MSE (입력 x_init 대비 복원 x_hat)\n",
    "\n",
    "class SAGEAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3, aggr=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.sage1 = SAGEConv(in_channels=in_dim, out_channels=256, aggr=aggr)\n",
    "        self.sage2 = SAGEConv(in_channels=256, out_channels=32, aggr=aggr)\n",
    "        self.sage3 = SAGEConv(in_channels=32, out_channels=64, aggr=aggr)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.sage2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.sage3(x, edge_index)  # 복원 64d (보통 마지막은 활성 미적용)\n",
    "        return x\n",
    "\n",
    "model = SAGEAutoEncoder(in_dim=64, dropout=0.3, aggr=\"mean\").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) 학습 (1000 epoch, MSE 재구성오차 최소화)\n",
    "x_in = x_init.to(DEVICE)\n",
    "\n",
    "def train_sage_ae(epochs=1000):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        optimizer.zero_grad()\n",
    "        x_hat = model(x_in, data.edge_index)\n",
    "        loss = F.mse_loss(x_hat, x_in)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 50 == 0 or epoch == 1:\n",
    "            print(f\"[SAGE-AE] epoch {epoch:04d} | recon MSE {loss.item():.6f}\")\n",
    "\n",
    "train_sage_ae(epochs=1000)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) 재구성오차 → z-score → 상위 5% 이상치\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_recon = model(x_in, data.edge_index)\n",
    "\n",
    "recon_err = torch.mean((x_recon - x_in)**2, dim=1).detach().cpu().numpy()\n",
    "mu = recon_err.mean()\n",
    "sigma = recon_err.std(ddof=1) if recon_err.size > 1 else 1e-8\n",
    "z = (recon_err - mu) / (sigma if sigma > 0 else 1e-8)\n",
    "\n",
    "z_cut = np.percentile(z, 95.0)\n",
    "anom = (z > z_cut).astype(int)\n",
    "\n",
    "print(f\"상위 5% z-score 임계값: {z_cut:.4f}\")\n",
    "print(f\"이상치 노드 수: {anom.sum()} / {len(anom)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) 결과 저장\n",
    "out = pd.DataFrame({\n",
    "    \"address\": addresses,\n",
    "    \"recon_mse\": recon_err,\n",
    "    \"z_score\": z,\n",
    "    \"is_anomaly_top5pct\": anom\n",
    "})\n",
    "out.sort_values(\"z_score\", ascending=False).to_csv(\"sage_ae_anomalies.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "torch.save(model.state_dict(), \"sage_autoencoder.pt\")\n",
    "np.save(\"node2vec_embeddings_sage.npy\", x_init.detach().cpu().numpy())\n",
    "\n",
    "print(\"✅ 완료: sage_ae_anomalies.csv / sage_autoencoder.pt / node2vec_embeddings_sage.npy 생성\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
