그래프 데이터베이스 분석
제 1 절 AI 기반 이상 거래 패턴 분석
1. 그래프 신경망 모델(GAT)
본 연구에서 사용한 GAT(Graph Attention Network) 모델은 오토인코더구조(3개 층)로 되어 있다. GAT 모델은 그래프로 변환된 PICA 트랜잭션의 64차원 벡터를 입력으로 받아, 어텐션 메커니즘을 통해 노드 간의 중요도를 학습하며 차원 변환(64→256→32→64)을 거쳐 그래프의 구조와 각노드의 속성 정보를 학습한다. 학습된 GAT 모델은 입력 데이터를 재구성하고, 재구성된 벡터와 원본 입력 벡터 간의 오차(재구성 오차)를 계산하여 이상 거래 패턴을 탐지한다.
1.1 오토인코더(Auto Encoder)
오토인코더(Autoencoder)는 인코더와 디코더로 구성된 신경망 구조로,
입력 데이터를 저차원 공간으로 압축(인코딩)한 뒤 이를 다시 원래 차원으로 복원(디코딩)하는 과정을 통해 데이터의 주요 특징을 학습하는 비지도 학습 모델이다. 오토인코더는 학습 과정에서 재구성 오차(Reconstructi
on Error)를 최소화하는 것을 목표로 하며, 이때 손실 함수로는 주로 평균 제곱 오차(MSE)가 사용된다.
1.2 GAT 모델 구조 및 설정
GAT 모델의 각 층 사이에서 활성화 함수는 ELU를 사용하고, 드롭아웃은 0.3을 적용한다. 학습은 Adam 알고리즘(학습률=0.001)을 사용하며, 과
- 23 -
파라미터 값 설 명
최적화 설정
최적화 알고리즘 Adam 파라미터 업데이트 알고리즘
학습률 0.001 학습 속도 조절 값
가중치 감쇠 0.0005 가중치 업데이트 감쇠율
손실 함수 속성 MSE 예측 오차 계산 함수
학습 구성
최대 에폭 500 전체 데이터 학습 반복 횟수
드롭아웃 비율 0.3 학습 중 뉴런 비활성화 비율
적합 방지를 위해 가중치 감쇠(Weight Decay)는 0.0005를 적용한다.
[표 5] GAT 모델 파라미터
1.3 입력변수
GAT 모델의 입력 데이터는 그래프로 변환된 PICA 트랜잭션 데이터를Node2vec 기법으로 학습하여 생성한 64차원 임베딩 벡터 값이다.
1. GAT 모델 학습
2.1 그래프 임베딩
본 연구에서는 PICA 트랜잭션 데이터를 그래프로 변환한 후, Node2Vec
기법을 사용하여 각 노드의 속성 정보10)(35가지 속성)와 그래프 구조를학습하여 64차원 벡터로 임베딩하였다. Node2Vec에 적용된 파라미터는다음과 같다.
2. 그래프 데이터베이스 모델링 단계에서 지갑 주소 노드(addr)에 추가한 37가지 속성 중 firstTransaction과 lastTransaction을 제외한 나머지 35가지 속성
- 24 -
파라미터 값 설명
임베딩 설정
dimensions 64 임베딩 차원 수
window 10 컨텍스트 윈도우 크기
min_count 1 최소 등장 횟수
batch_words 4 배치 크기
랜덤워크 설정
walk_length 30 랜덤 워크 길이
num_walks 200 랜덤 워크 횟수
workers 4 병렬 처리 시 사용되는 워커 수
p 1 이전 노드 반환 경향(균형)
q 1 DFS, BFS 탐색 방식(균형)
[표 6] Node2Vec 파라미터
2.2 모델 학습
본 연구의 GAT 모델은 3개의 층(Layer)으로 구성되어 학습을 수행한다.
첫 번째 층에서는 각 노드의 64차원 벡터를 입력받아 8개의 어텐션 헤드를 통해 이웃 노드의 중요도를 반영하며 학습한 뒤, 256차원 벡터를 출력한다. 두 번째 층에서는 첫 번째 층의 256차원 벡터를 입력받아 1개의 어텐션 헤드를 통해 학습하여 32차원으로 압축한다. 마지막 층에서는 두 번째 층의 32차원 벡터를 입력받아 1개의 어텐션 헤드를 통해 원본 데이터와 동일한 64차원 벡터로 복원한다.
모델 학습은 총 1,000 에폭(Epoch) 동안 진행되며, 재구성 오차를 최소화하기 위해 평균 제곱 오차(MSE)를 손실 함수로 사용한다.