{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8370a2d5",
   "metadata": {},
   "source": [
    "### 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add torch torch_geometric pandas networkx numpy python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0ebeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b2cc2",
   "metadata": {},
   "source": [
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# --------------------------------\n",
    "# 설정\n",
    "# --------------------------------\n",
    "API_KEY = os.getenv('ETHEREUM_API_KEY')  # Etherscan API 키 입력\n",
    "CONTRACT = os.getenv('ETHEREUM_TOKEN_CONTRACT_ADDRESS')  # PicaArtMoney 토큰 컨트랙트\n",
    "START_DATE = \"2020-10-13\"\n",
    "END_DATE   = \"2024-08-07\"\n",
    "\n",
    "# --------------------------\n",
    "# 유틸: UTC 타임스탬프 변환\n",
    "# --------------------------\n",
    "def to_ts_utc(dstr: str) -> int:\n",
    "    y, m, d = map(int, dstr.split(\"-\"))\n",
    "    return int(datetime(y, m, d, tzinfo=timezone.utc).timestamp())\n",
    "\n",
    "start_ts = to_ts_utc(START_DATE)\n",
    "end_ts   = to_ts_utc(END_DATE)\n",
    "\n",
    "# --------------------------\n",
    "# 블록 번호 by timestamp\n",
    "# --------------------------\n",
    "def get_block_number_by_timestamp(ts: int, closest=\"before\") -> int:\n",
    "    url = \"https://api.etherscan.io/api\"\n",
    "    params = {\n",
    "        \"module\": \"block\",\n",
    "        \"action\": \"getblocknobytime\",\n",
    "        \"timestamp\": ts,\n",
    "        \"closest\": closest,\n",
    "        \"apikey\": API_KEY\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30).json()\n",
    "    return int(r[\"result\"])\n",
    "\n",
    "start_block = get_block_number_by_timestamp(start_ts, \"after\")\n",
    "end_block   = get_block_number_by_timestamp(end_ts, \"before\")\n",
    "print(f\"[INFO] Block range: {start_block} ~ {end_block}\")\n",
    "\n",
    "# --------------------------\n",
    "# 페이지 호출 (재시도 포함)\n",
    "# --------------------------\n",
    "def fetch_transfers_page(page, offset, start_block, end_block):\n",
    "    url = \"https://api.etherscan.io/api\"\n",
    "    params = {\n",
    "        \"module\": \"account\",\n",
    "        \"action\": \"tokentx\",\n",
    "        \"contractaddress\": CONTRACT,\n",
    "        \"startblock\": start_block,\n",
    "        \"endblock\": end_block,\n",
    "        \"page\": page,\n",
    "        \"offset\": offset,\n",
    "        \"sort\": \"asc\",\n",
    "        \"apikey\": API_KEY\n",
    "    }\n",
    "    # 간단 재시도\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            resp = requests.get(url, params=params, timeout=30).json()\n",
    "            # status==\"1\"이면 결과, \"0\"이면 없음(또는 rate limit)\n",
    "            if resp.get(\"status\") == \"1\":\n",
    "                return resp[\"result\"]\n",
    "            # \"Max rate limit reached\" 같은 메시지면 잠깐 대기 후 재시도\n",
    "            if \"Max rate limit reached\" in resp.get(\"message\",\"\"):\n",
    "                time.sleep(1.0 * (i+1))\n",
    "                continue\n",
    "            return []\n",
    "        except Exception:\n",
    "            time.sleep(1.0 * (i+1))\n",
    "    return []\n",
    "\n",
    "# --------------------------\n",
    "# 범위 수집 (빈 청크도 로그)\n",
    "# --------------------------\n",
    "all_txs = []\n",
    "step = 200_000        # 블록 청크 크기\n",
    "offset = 10_000       # 페이지 크기\n",
    "sleep_s = 0.25        # rate limit 보호\n",
    "current = start_block\n",
    "\n",
    "# (선택) 처리한 청크 목록 보관해 누락 시각화\n",
    "processed_ranges = []\n",
    "\n",
    "while current <= end_block:\n",
    "    to_block = min(current + step - 1, end_block)\n",
    "    processed_ranges.append((current, to_block))\n",
    "\n",
    "    page = 1\n",
    "    new_cnt = 0\n",
    "    while True:\n",
    "        txs = fetch_transfers_page(page, offset, current, to_block)\n",
    "        if not txs:\n",
    "            # 첫 페이지부터 빈 경우 → 이 청크엔 트랜잭션 없음을 명시\n",
    "            if page == 1:\n",
    "                print(f\"[INFO] Blocks {current}–{to_block}, Page {page}, NO TX\")\n",
    "            break\n",
    "\n",
    "        # 기간 필터\n",
    "        for tx in txs:\n",
    "            ts = int(tx.get(\"timeStamp\", 0))\n",
    "            if start_ts <= ts <= end_ts:\n",
    "                all_txs.append(tx)\n",
    "                new_cnt += 1\n",
    "\n",
    "        print(f\"[INFO] Blocks {current}–{to_block}, Page {page}, Added {new_cnt}, Total {len(all_txs)}\")\n",
    "        page += 1\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "        # 마지막 페이지(=반환건수 < offset) 판단 → 더 이상 이 청크에서 페이지 없음\n",
    "        if len(txs) < offset:\n",
    "            break\n",
    "\n",
    "    current = to_block + 1  # 다음 청크로\n",
    "\n",
    "# --------------------------\n",
    "# DataFrame & 중복 제거\n",
    "# --------------------------\n",
    "df = pd.DataFrame(all_txs)\n",
    "\n",
    "# 어떤 컬럼이 있는지 확인\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "# 존재하는 컬럼만으로 중복 제거\n",
    "subset_cols = [c for c in [\"hash\", \"logIndex\", \"transactionIndex\"] if c in df.columns]\n",
    "if subset_cols:\n",
    "    df.drop_duplicates(subset=subset_cols, inplace=True)\n",
    "else:\n",
    "    df.drop_duplicates(subset=[\"hash\"], inplace=True)\n",
    "\n",
    "# (선택) amount 컬럼 추가\n",
    "if {\"value\",\"tokenDecimal\"} <= set(df.columns):\n",
    "    df[\"amount\"] = (df[\"value\"].astype(\"int64\") /\n",
    "                    (10 ** df[\"tokenDecimal\"].astype(int)))\n",
    "else:\n",
    "    df[\"amount\"] = 0.0\n",
    "\n",
    "out_path = \"picaartmoney_transactions_full.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"[INFO] Finished. Total collected: {len(df)} transactions → {out_path}\")\n",
    "\n",
    "# --------------------------\n",
    "# (선택) 누락 구간 시각 확인용\n",
    "# --------------------------\n",
    "# 빈 청크도 NO TX 로그가 찍히므로, 처리 범위가 연속적이라면 누락은 없습니다.\n",
    "# 그래도 안심용으로 연속성 체크:\n",
    "gaps = []\n",
    "for (a1,b1),(a2,b2) in zip(processed_ranges, processed_ranges[1:]):\n",
    "    if a2 != b1 + 1:\n",
    "        gaps.append((b1+1, a2-1))\n",
    "if gaps:\n",
    "    print(\"[WARN] Detected block gaps in iteration (should not happen):\", gaps)\n",
    "else:\n",
    "    print(\"[INFO] No block range gaps in iteration (every chunk covered).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fd7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fa2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Block range: 11043877 ~ 20472970\n",
      "[INFO] Blocks 11043877–11243876, Page 1, Added 3828, Total 3828\n",
      "[INFO] Blocks 11243877–11443876, Page 1, Added 238, Total 4066\n",
      "[INFO] Blocks 11443877–11643876, Page 1, Added 321, Total 4387\n",
      "[INFO] Blocks 11643877–11843876, Page 1, Added 2973, Total 7360\n",
      "[INFO] Blocks 11843877–12043876, Page 1, Added 2121, Total 9481\n",
      "[INFO] Blocks 12043877–12243876, Page 1, Added 5185, Total 14666\n",
      "[INFO] Blocks 12243877–12443876, Page 1, Added 2273, Total 16939\n",
      "[INFO] Blocks 12443877–12643876, Page 1, Added 1210, Total 18149\n",
      "[INFO] Blocks 12643877–12843876, Page 1, Added 3398, Total 21547\n",
      "[INFO] Blocks 12843877–13043876, Page 1, Added 1086, Total 22633\n",
      "[INFO] Blocks 13043877–13243876, Page 1, Added 220, Total 22853\n",
      "[INFO] Blocks 13243877–13443876, Page 1, Added 144, Total 22997\n",
      "[INFO] Blocks 13443877–13643876, Page 1, Added 3338, Total 26335\n",
      "[INFO] Blocks 13643877–13843876, Page 1, Added 38, Total 26373\n",
      "[INFO] Blocks 13843877–14043876, Page 1, Added 10, Total 26383\n",
      "[INFO] Blocks 14043877–14243876, Page 1, Added 9, Total 26392\n",
      "[INFO] Blocks 14243877–14443876, Page 1, Added 36, Total 26428\n",
      "[INFO] Blocks 14443877–14643876, Page 1, Added 12, Total 26440\n",
      "[INFO] Blocks 14643877–14843876, Page 1, Added 8, Total 26448\n",
      "[INFO] Blocks 14843877–15043876, Page 1, Added 2, Total 26450\n",
      "[INFO] Blocks 15043877–15243876, Page 1, Added 18, Total 26468\n",
      "[INFO] Blocks 15243877–15443876, Page 1, Added 9, Total 26477\n",
      "[INFO] Blocks 15443877–15643876, Page 1, Added 8, Total 26485\n",
      "[INFO] Blocks 15643877–15843876, Page 1, Added 3, Total 26488\n",
      "[INFO] Blocks 15843877–16043876, Page 1, Added 11, Total 26499\n",
      "[INFO] Blocks 16043877–16243876, Page 1, Added 22, Total 26521\n",
      "[INFO] Blocks 16243877–16443876, Page 1, Added 13, Total 26534\n",
      "[INFO] Blocks 16443877–16643876, Page 1, Added 5, Total 26539\n",
      "[INFO] Blocks 16643877–16843876, Page 1, Added 14, Total 26553\n",
      "[INFO] Blocks 16843877–17043876, Page 1, NO TX\n",
      "[INFO] Blocks 17043877–17243876, Page 1, Added 2, Total 26555\n",
      "[INFO] Blocks 17243877–17443876, Page 1, NO TX\n",
      "[INFO] Blocks 17443877–17643876, Page 1, NO TX\n",
      "[INFO] Blocks 17643877–17843876, Page 1, Added 1, Total 26556\n",
      "[INFO] Blocks 17843877–18043876, Page 1, NO TX\n",
      "[INFO] Blocks 18043877–18243876, Page 1, NO TX\n",
      "[INFO] Blocks 18243877–18443876, Page 1, NO TX\n",
      "[INFO] Blocks 18443877–18643876, Page 1, NO TX\n",
      "[INFO] Blocks 18643877–18843876, Page 1, Added 2, Total 26558\n",
      "[INFO] Blocks 18843877–19043876, Page 1, Added 8, Total 26566\n",
      "[INFO] Blocks 19043877–19243876, Page 1, Added 2, Total 26568\n",
      "[INFO] Blocks 19243877–19443876, Page 1, Added 2, Total 26570\n",
      "[INFO] Blocks 19443877–19643876, Page 1, Added 8, Total 26578\n",
      "[INFO] Blocks 19643877–19843876, Page 1, Added 4, Total 26582\n",
      "[INFO] Blocks 19843877–20043876, Page 1, Added 6, Total 26588\n",
      "[INFO] Blocks 20043877–20243876, Page 1, NO TX\n",
      "[INFO] Blocks 20243877–20443876, Page 1, Added 4, Total 26592\n",
      "[INFO] Blocks 20443877–20472970, Page 1, NO TX\n",
      "[INFO] Columns: ['blockNumber', 'timeStamp', 'hash', 'nonce', 'blockHash', 'from', 'contractAddress', 'to', 'value', 'tokenName', 'tokenSymbol', 'tokenDecimal', 'transactionIndex', 'gas', 'gasPrice', 'gasUsed', 'cumulativeGasUsed', 'input', 'methodId', 'functionName', 'confirmations']\n",
      "[INFO] Finished. Total collected: 25603 transactions → picaartmoney_transactions_full.csv\n",
      "[INFO] No block range gaps in iteration (every chunk covered).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e549a34",
   "metadata": {},
   "source": [
    "### 수집 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cd43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0) Imports\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GAE\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "import networkx as nx\n",
    "from decimal import Decimal, getcontext\n",
    "from datetime import datetime, timezone\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718a3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 파일 경로\n",
    "CSV_PATH = \"picaartmoney_transactions_full.csv\"\n",
    "USE_COLS = [\n",
    "    'blockNumber','timeStamp','hash','nonce','blockHash','from','contractAddress','to','value',\n",
    "    'tokenName','tokenSymbol','tokenDecimal','transactionIndex','gas','gasPrice','gasUsed',\n",
    "    'cumulativeGasUsed','input','confirmations'\n",
    "]\n",
    "\n",
    "# 소수 정밀도 (ETH/토큰 소수 처리 안전하게)\n",
    "getcontext().prec = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc58294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockNumber</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>hash</th>\n",
       "      <th>nonce</th>\n",
       "      <th>blockHash</th>\n",
       "      <th>from</th>\n",
       "      <th>contractAddress</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "      <th>tokenName</th>\n",
       "      <th>...</th>\n",
       "      <th>transactionIndex</th>\n",
       "      <th>gas</th>\n",
       "      <th>gasPrice</th>\n",
       "      <th>gasUsed</th>\n",
       "      <th>cumulativeGasUsed</th>\n",
       "      <th>input</th>\n",
       "      <th>confirmations</th>\n",
       "      <th>timestamp_dt</th>\n",
       "      <th>value_float</th>\n",
       "      <th>gas_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11085582</td>\n",
       "      <td>1603098539</td>\n",
       "      <td>0x328008e17407b6ba014295bfe5069ba4f60f1296aea0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0x7185066660404b22f7f1cac0862c8a7f5c1ef99e4a1f...</td>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "      <td>0xa7e0719a65128b2f6cdbc86096753ff7d5962106</td>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>PicaArtMoney</td>\n",
       "      <td>...</td>\n",
       "      <td>251</td>\n",
       "      <td>1603895</td>\n",
       "      <td>36000000000</td>\n",
       "      <td>1603895</td>\n",
       "      <td>11088223</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>12287913</td>\n",
       "      <td>2020-10-19 09:08:59+00:00</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>1603895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11091306</td>\n",
       "      <td>1603174037</td>\n",
       "      <td>0xa8352e8094fb444e9bfa9a4a6d8011502a0f4655ad38...</td>\n",
       "      <td>1</td>\n",
       "      <td>0x6902d2e0773fd0bad116b753b98e37d61d7a4b532d71...</td>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>0xa7e0719a65128b2f6cdbc86096753ff7d5962106</td>\n",
       "      <td>0xfa9b57cbe5b7bd63b436dcf205c15222b510ff27</td>\n",
       "      <td>150000000</td>\n",
       "      <td>PicaArtMoney</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>53110</td>\n",
       "      <td>26000000000</td>\n",
       "      <td>53110</td>\n",
       "      <td>12360057</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>12282189</td>\n",
       "      <td>2020-10-20 06:07:17+00:00</td>\n",
       "      <td>150000000</td>\n",
       "      <td>53110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11091306</td>\n",
       "      <td>1603174037</td>\n",
       "      <td>0x36195c14399493bdf43387ded77d87d3b5e98c94a138...</td>\n",
       "      <td>2</td>\n",
       "      <td>0x6902d2e0773fd0bad116b753b98e37d61d7a4b532d71...</td>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>0xa7e0719a65128b2f6cdbc86096753ff7d5962106</td>\n",
       "      <td>0x32f042b0b01f10247493a950456f4c4304d46ba5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>PicaArtMoney</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>53110</td>\n",
       "      <td>26000000000</td>\n",
       "      <td>53110</td>\n",
       "      <td>12413167</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>12282189</td>\n",
       "      <td>2020-10-20 06:07:17+00:00</td>\n",
       "      <td>150000000</td>\n",
       "      <td>53110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11091306</td>\n",
       "      <td>1603174037</td>\n",
       "      <td>0xbf52a2c6de897287b5c6740c891a71a5122c69566bdb...</td>\n",
       "      <td>3</td>\n",
       "      <td>0x6902d2e0773fd0bad116b753b98e37d61d7a4b532d71...</td>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>0xa7e0719a65128b2f6cdbc86096753ff7d5962106</td>\n",
       "      <td>0xd4b394c60bb55f80df30dac87b6f92be34739332</td>\n",
       "      <td>300000000</td>\n",
       "      <td>PicaArtMoney</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>53098</td>\n",
       "      <td>26000000000</td>\n",
       "      <td>53098</td>\n",
       "      <td>12466265</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>12282189</td>\n",
       "      <td>2020-10-20 06:07:17+00:00</td>\n",
       "      <td>300000000</td>\n",
       "      <td>53098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11091313</td>\n",
       "      <td>1603174087</td>\n",
       "      <td>0x246a4998919d4c369ff0735ea372729a9e06199055e1...</td>\n",
       "      <td>4</td>\n",
       "      <td>0xe18ff0b2e114d21a3f5cf8c2976342cea2fc558254ee...</td>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>0xa7e0719a65128b2f6cdbc86096753ff7d5962106</td>\n",
       "      <td>0xc32b1345acae345c595d3bbcf62e14e5f3020456</td>\n",
       "      <td>200000000</td>\n",
       "      <td>PicaArtMoney</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>53098</td>\n",
       "      <td>27000000000</td>\n",
       "      <td>53098</td>\n",
       "      <td>5923677</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>12282182</td>\n",
       "      <td>2020-10-20 06:08:07+00:00</td>\n",
       "      <td>200000000</td>\n",
       "      <td>53098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  blockNumber   timeStamp                                               hash  \\\n",
       "0    11085582  1603098539  0x328008e17407b6ba014295bfe5069ba4f60f1296aea0...   \n",
       "1    11091306  1603174037  0xa8352e8094fb444e9bfa9a4a6d8011502a0f4655ad38...   \n",
       "2    11091306  1603174037  0x36195c14399493bdf43387ded77d87d3b5e98c94a138...   \n",
       "3    11091306  1603174037  0xbf52a2c6de897287b5c6740c891a71a5122c69566bdb...   \n",
       "4    11091313  1603174087  0x246a4998919d4c369ff0735ea372729a9e06199055e1...   \n",
       "\n",
       "  nonce                                          blockHash  \\\n",
       "0     0  0x7185066660404b22f7f1cac0862c8a7f5c1ef99e4a1f...   \n",
       "1     1  0x6902d2e0773fd0bad116b753b98e37d61d7a4b532d71...   \n",
       "2     2  0x6902d2e0773fd0bad116b753b98e37d61d7a4b532d71...   \n",
       "3     3  0x6902d2e0773fd0bad116b753b98e37d61d7a4b532d71...   \n",
       "4     4  0xe18ff0b2e114d21a3f5cf8c2976342cea2fc558254ee...   \n",
       "\n",
       "                                         from  \\\n",
       "0  0x0000000000000000000000000000000000000000   \n",
       "1  0xd28493e737fbcc957f3716143ed6e40f40357b51   \n",
       "2  0xd28493e737fbcc957f3716143ed6e40f40357b51   \n",
       "3  0xd28493e737fbcc957f3716143ed6e40f40357b51   \n",
       "4  0xd28493e737fbcc957f3716143ed6e40f40357b51   \n",
       "\n",
       "                              contractAddress  \\\n",
       "0  0xa7e0719a65128b2f6cdbc86096753ff7d5962106   \n",
       "1  0xa7e0719a65128b2f6cdbc86096753ff7d5962106   \n",
       "2  0xa7e0719a65128b2f6cdbc86096753ff7d5962106   \n",
       "3  0xa7e0719a65128b2f6cdbc86096753ff7d5962106   \n",
       "4  0xa7e0719a65128b2f6cdbc86096753ff7d5962106   \n",
       "\n",
       "                                           to       value     tokenName  ...  \\\n",
       "0  0xd28493e737fbcc957f3716143ed6e40f40357b51  1000000000  PicaArtMoney  ...   \n",
       "1  0xfa9b57cbe5b7bd63b436dcf205c15222b510ff27   150000000  PicaArtMoney  ...   \n",
       "2  0x32f042b0b01f10247493a950456f4c4304d46ba5   150000000  PicaArtMoney  ...   \n",
       "3  0xd4b394c60bb55f80df30dac87b6f92be34739332   300000000  PicaArtMoney  ...   \n",
       "4  0xc32b1345acae345c595d3bbcf62e14e5f3020456   200000000  PicaArtMoney  ...   \n",
       "\n",
       "  transactionIndex      gas     gasPrice  gasUsed  cumulativeGasUsed  \\\n",
       "0              251  1603895  36000000000  1603895           11088223   \n",
       "1              185    53110  26000000000    53110           12360057   \n",
       "2              186    53110  26000000000    53110           12413167   \n",
       "3              187    53098  26000000000    53098           12466265   \n",
       "4              100    53098  27000000000    53098            5923677   \n",
       "\n",
       "        input confirmations              timestamp_dt value_float gas_used  \n",
       "0  deprecated      12287913 2020-10-19 09:08:59+00:00  1000000000  1603895  \n",
       "1  deprecated      12282189 2020-10-20 06:07:17+00:00   150000000    53110  \n",
       "2  deprecated      12282189 2020-10-20 06:07:17+00:00   150000000    53110  \n",
       "3  deprecated      12282189 2020-10-20 06:07:17+00:00   300000000    53098  \n",
       "4  deprecated      12282182 2020-10-20 06:08:07+00:00   200000000    53098  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0) CSV 로드 & 전처리\n",
    "df = pd.read_csv(CSV_PATH, usecols=USE_COLS, dtype=str)\n",
    "\n",
    "# 결측/공백 안전 처리\n",
    "for col in ['from', 'to']:\n",
    "    df[col] = df[col].fillna('').str.strip().str.lower()\n",
    "\n",
    "# timestamp -> int / datetime\n",
    "df['timeStamp'] = pd.to_numeric(df['timeStamp'], errors='coerce')\n",
    "df = df.dropna(subset=['timeStamp'])\n",
    "df['timestamp_dt'] = pd.to_datetime(df['timeStamp'], unit='s', utc=True)\n",
    "\n",
    "# 숫자형 컬럼 변환\n",
    "for c in ['value', 'tokenDecimal', 'gas', 'gasPrice', 'gasUsed']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n",
    "\n",
    "# value → 정규화 (value / 10**tokenDecimal)\n",
    "def safe_value(row):\n",
    "    try:\n",
    "        dec = int(row['tokenDecimal'])\n",
    "        val = Decimal(int(row['value'])) / (Decimal(10) ** dec)\n",
    "        return val\n",
    "    except Exception:\n",
    "        return Decimal(0)\n",
    "\n",
    "df['value_float'] = df.apply(safe_value, axis=1)\n",
    "\n",
    "# gasUsed 우선 사용 (없으면 gas)\n",
    "df['gas_used'] = np.where(df['gasUsed'] > 0, df['gasUsed'], df['gas'])\n",
    "\n",
    "# 송/수신이 비어있거나 동일지갑 자기전송은 제외(원하면 포함 가능)\n",
    "df = df[(df['from'] != '') & (df['to'] != '') & (df['from'] != df['to'])]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf681b",
   "metadata": {},
   "source": [
    "### 그래프데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be752bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 기본엣지 그래프 (MultiDiGraph) 구축\n",
    "G_base = nx.MultiDiGraph()\n",
    "# 노드 추가(지갑주소)\n",
    "nodes = pd.unique(pd.concat([df['from'], df['to']], ignore_index=True))\n",
    "G_base.add_nodes_from(nodes)\n",
    "\n",
    "# 엣지 추가(트랜잭션 단위)\n",
    "for _, r in df.iterrows():\n",
    "    G_base.add_edge(\n",
    "        r['from'], r['to'],\n",
    "        key=r['hash'],\n",
    "        hash=r['hash'],\n",
    "        timestamp=int(r['timeStamp']),\n",
    "        timestamp_dt=r['timestamp_dt'],\n",
    "        value_float=r['value_float'],\n",
    "        gas_used=int(r['gas_used'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 총괄엣지 그래프 (무방향, 계좌쌍 집계)\n",
    "# net_value: sum(A->B) - sum(B->A), tx_count: 총 거래 횟수, first_tx_time: 최소 시각\n",
    "pair_sum_ab = defaultdict(Decimal)   # sum A->B\n",
    "pair_sum_ba = defaultdict(Decimal)   # sum B->A\n",
    "pair_count = Counter()\n",
    "pair_first_ts = dict()\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    a, b = r['from'], r['to']\n",
    "    key = tuple(sorted((a, b)))\n",
    "    pair_count[key] += 1\n",
    "    ts = int(r['timeStamp'])\n",
    "    if key not in pair_first_ts or ts < pair_first_ts[key]:\n",
    "        pair_first_ts[key] = ts\n",
    "    # 방향 합계\n",
    "    if a < b:\n",
    "        # 저장은 작은주소,큰주소 기준으로 해두고 방향은 따로 기록\n",
    "        pair_sum_ab[key] += r['value_float']  # a(작은?)→b(큰?)가 아닐 수 있어 아래에서 다시 방향판단\n",
    "    else:\n",
    "        pair_sum_ba[key] += r['value_float']\n",
    "\n",
    "# 더 명확하게 재집계:\n",
    "pair_dir_sum = defaultdict(lambda: {'ab': Decimal(0), 'ba': Decimal(0)})\n",
    "for _, r in df.iterrows():\n",
    "    a, b = r['from'], r['to']\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if (a, b) == key:\n",
    "        pair_dir_sum[key]['ab'] += r['value_float']\n",
    "    else:\n",
    "        pair_dir_sum[key]['ba'] += r['value_float']\n",
    "\n",
    "H_summary = nx.Graph()\n",
    "H_summary.add_nodes_from(nodes)\n",
    "\n",
    "for key in pair_count.keys():\n",
    "    a, b = key\n",
    "    ab = pair_dir_sum[key]['ab']\n",
    "    ba = pair_dir_sum[key]['ba']\n",
    "    net_value = ab - ba\n",
    "    first_ts = pair_first_ts[key]\n",
    "    H_summary.add_edge(\n",
    "        a, b,\n",
    "        net_value=float(net_value),         # CSV 저장 편의 위해 float 캐스팅(정밀 보존 원하면 str(net_value))\n",
    "        tx_count=int(pair_count[key]),\n",
    "        first_tx_time=int(first_ts)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) 노드 특성 계산 (29개)\n",
    "# 준비: 방향 기준별 집계\n",
    "# 노드별 in/out 트랜잭션 수/금액/가스\n",
    "in_count = Counter()\n",
    "out_count = Counter()\n",
    "in_amount_sum = defaultdict(Decimal)\n",
    "out_amount_sum = defaultdict(Decimal)\n",
    "in_gas_sum = Counter()\n",
    "out_gas_sum = Counter()\n",
    "\n",
    "# 노드별 타임스탬프 모음\n",
    "node_timestamps = defaultdict(list)\n",
    "\n",
    "# 노드별 in/out 이웃(상대방) 집합\n",
    "in_neighbors = defaultdict(set)\n",
    "out_neighbors = defaultdict(set)\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    s, t = r['from'], r['to']\n",
    "    val = r['value_float']\n",
    "    gasu = int(r['gas_used'])\n",
    "    ts = int(r['timeStamp'])\n",
    "\n",
    "    # 카운트/합계\n",
    "    out_count[s] += 1\n",
    "    in_count[t] += 1\n",
    "    out_amount_sum[s] += val\n",
    "    in_amount_sum[t] += val\n",
    "    out_gas_sum[s] += gasu\n",
    "    in_gas_sum[t] += gasu\n",
    "\n",
    "    # 이웃\n",
    "    out_neighbors[s].add(t)\n",
    "    in_neighbors[t].add(s)\n",
    "\n",
    "    # 타임스탬프\n",
    "    node_timestamps[s].append(ts)\n",
    "    node_timestamps[t].append(ts)\n",
    "\n",
    "# 3-1) 유일 송/수신 상대 관련\n",
    "# - \"송신 트랜잭션의 유일한 상대방이 해당 노드인 노드들의 수 / 총 수량\"\n",
    "#   즉, X의 out_neighbors(X)가 {v}인 모든 X를 v 기준으로 집계\n",
    "unique_sender_targets = defaultdict(list)  # v -> [X,...] where X sends only to v\n",
    "for x, outs in out_neighbors.items():\n",
    "    if len(outs) == 1:\n",
    "        v = next(iter(outs))\n",
    "        unique_sender_targets[v].append(x)\n",
    "\n",
    "# 유일송신 총 수량(해당 X->v로 보낸 모든 금액 합)\n",
    "unique_send_total_amount_to_v = defaultdict(Decimal)\n",
    "for v, senders in unique_sender_targets.items():\n",
    "    # df 필터 비용 줄이려면 사전 집계를 쓰는 것이 좋지만, 데이터 건수가 2.6만이라도 충분히 처리 가능\n",
    "    mask = (df['from'].isin(senders)) & (df['to'] == v)\n",
    "    if mask.any():\n",
    "        unique_send_total_amount_to_v[v] = df.loc[mask, 'value_float'].sum()\n",
    "    else:\n",
    "        unique_send_total_amount_to_v[v] = Decimal(0)\n",
    "\n",
    "# - \"수신 트랜잭션의 유일한 상대발이 해당 노드인 노드들의 수 / 총 수량\"\n",
    "#   즉, Y의 in_neighbors(Y)가 {v}인 모든 Y를 v 기준으로 집계 (Y는 v에게서만 받음)\n",
    "unique_receiver_sources = defaultdict(list)  # v -> [Y,...] where Y receives only from v\n",
    "for y, ins in in_neighbors.items():\n",
    "    if len(ins) == 1:\n",
    "        v = next(iter(ins))\n",
    "        unique_receiver_sources[v].append(y)\n",
    "\n",
    "unique_recv_total_amount_from_v = defaultdict(Decimal)\n",
    "for v, receivers in unique_receiver_sources.items():\n",
    "    mask = (df['to'].isin(receivers)) & (df['from'] == v)\n",
    "    if mask.any():\n",
    "        unique_recv_total_amount_from_v[v] = df.loc[mask, 'value_float'].sum()\n",
    "    else:\n",
    "        unique_recv_total_amount_from_v[v] = Decimal(0)\n",
    "\n",
    "# 3-2) 순환 거래수: 같은 SCC 안의 상대와 주고받은 트랜잭션 수\n",
    "# (방향 그래프의 강결합요소 기반)\n",
    "sccs = list(nx.strongly_connected_components(G_base))\n",
    "comp_id = {}\n",
    "for i, comp in enumerate(sccs):\n",
    "    for n in comp:\n",
    "        comp_id[n] = i\n",
    "\n",
    "cycle_tx_count = Counter()\n",
    "for u, v, k, d in G_base.edges(keys=True, data=True):\n",
    "    if comp_id.get(u) == comp_id.get(v) and len(sccs[comp_id[u]]) > 1:\n",
    "        cycle_tx_count[u] += 1\n",
    "        cycle_tx_count[v] += 1\n",
    "\n",
    "# 3-3) 양방향 상대 수: u<->v 모두 존재하는 상대 수\n",
    "bidirectional_count = Counter()\n",
    "# 빠른 판별: 무방향으로 변환 후, 각 이웃 중 실제로 양방향 존재하는지 체크\n",
    "UG = G_base.to_undirected()\n",
    "for n in G_base.nodes():\n",
    "    cnt = 0\n",
    "    for nbr in UG.neighbors(n):\n",
    "        has_out = G_base.has_edge(n, nbr)\n",
    "        has_in = G_base.has_edge(nbr, n)\n",
    "        if has_out and has_in:\n",
    "            cnt += 1\n",
    "    bidirectional_count[n] = cnt\n",
    "\n",
    "# 3-4) 중심성들\n",
    "# Degree/Closeness/Betweenness: 무방향 그래프 기준\n",
    "deg_centrality = nx.degree_centrality(UG)\n",
    "# closeness는 연결요소 문제로 normalized=True 기본, 무방향에서 계산\n",
    "close_centrality = nx.closeness_centrality(UG)\n",
    "# betweenness: 계산 비용 큼. 노드 많으면 k-샘플링 사용 고려. 여기서는 정확 계산 시도.\n",
    "bet_centrality = nx.betweenness_centrality(UG, normalized=True)\n",
    "\n",
    "# PageRank: 방향 + 가중치(value_float)\n",
    "# weight가 float이어야 해서 미리 edge attr 준비 필요 → 이미 value_float 있음\n",
    "# MultiDiGraph이므로 가중치 합산 필요 → DiGraph로 합쳐서 가중치 누적\n",
    "DG_weighted = nx.DiGraph()\n",
    "for u, v, d in G_base.edges(data=True):\n",
    "    w = float(d.get('value_float', 0))\n",
    "    if w <= 0:\n",
    "        continue\n",
    "    if DG_weighted.has_edge(u, v):\n",
    "        DG_weighted[u][v]['weight'] += w\n",
    "    else:\n",
    "        DG_weighted.add_edge(u, v, weight=w)\n",
    "\n",
    "if DG_weighted.number_of_edges() > 0:\n",
    "    pagerank = nx.pagerank(DG_weighted, weight='weight')\n",
    "else:\n",
    "    pagerank = {n: 0.0 for n in G_base.nodes()}\n",
    "\n",
    "# 3-5) 나머지 지표들 조립\n",
    "rows = []\n",
    "for n in G_base.nodes():\n",
    "    in_neigh = in_neighbors.get(n, set())\n",
    "    out_neigh = out_neighbors.get(n, set())\n",
    "\n",
    "    total_in_cnt = in_count.get(n, 0)\n",
    "    total_out_cnt = out_count.get(n, 0)\n",
    "    total_in_amt = in_amount_sum.get(n, Decimal(0))\n",
    "    total_out_amt = out_amount_sum.get(n, Decimal(0))\n",
    "    total_in_gas = in_gas_sum.get(n, 0)\n",
    "    total_out_gas = out_gas_sum.get(n, 0)\n",
    "\n",
    "    # 평균들(0 나눗셈 방지)\n",
    "    avg_in_amt = (total_in_amt / total_in_cnt) if total_in_cnt > 0 else Decimal(0)\n",
    "    avg_out_amt = (total_out_amt / total_out_cnt) if total_out_cnt > 0 else Decimal(0)\n",
    "    avg_in_gas = (Decimal(total_in_gas) / total_in_cnt) if total_in_cnt > 0 else Decimal(0)\n",
    "    avg_out_gas = (Decimal(total_out_gas) / total_out_cnt) if total_out_cnt > 0 else Decimal(0)\n",
    "\n",
    "    # 가스 효율\n",
    "    recv_gas_eff = (total_in_amt / Decimal(total_in_gas)) if total_in_gas > 0 else Decimal(0)\n",
    "    send_gas_eff = (total_out_amt / Decimal(total_out_gas)) if total_out_gas > 0 else Decimal(0)\n",
    "\n",
    "    # 활동 일수/일평균\n",
    "    ts_list = node_timestamps.get(n, [])\n",
    "    unique_days = set()\n",
    "    for ts in ts_list:\n",
    "        d = datetime.fromtimestamp(ts, tz=timezone.utc).date()\n",
    "        unique_days.add(d)\n",
    "    active_days = len(unique_days)\n",
    "    total_tx_cnt = total_in_cnt + total_out_cnt\n",
    "    total_amt_abs = total_in_amt + total_out_amt  # 필요시 abs 합으로 바꾸고 싶으면 수정\n",
    "    tx_per_day = (total_tx_cnt / active_days) if active_days > 0 else 0\n",
    "    amt_per_day = (total_amt_abs / Decimal(active_days)) if active_days > 0 else Decimal(0)\n",
    "\n",
    "    # 유일 송/수신 관련\n",
    "    uniq_send_nodes = unique_sender_targets.get(n, [])\n",
    "    uniq_recv_nodes = unique_receiver_sources.get(n, [])\n",
    "\n",
    "    uniq_send_count = len(uniq_send_nodes)\n",
    "    uniq_recv_count = len(uniq_recv_nodes)\n",
    "    uniq_send_amount = unique_send_total_amount_to_v.get(n, Decimal(0))\n",
    "    uniq_recv_amount = unique_recv_total_amount_from_v.get(n, Decimal(0))\n",
    "\n",
    "    # 순환 거래수/양방향 상대수\n",
    "    cyc_cnt = cycle_tx_count.get(n, 0)\n",
    "    bidi_cnt = bidirectional_count.get(n, 0)\n",
    "\n",
    "    # 중심성\n",
    "    deg_c = deg_centrality.get(n, 0.0)\n",
    "    clo_c = close_centrality.get(n, 0.0)\n",
    "    bet_c = bet_centrality.get(n, 0.0)\n",
    "    pr = pagerank.get(n, 0.0)\n",
    "\n",
    "    # 첫/마지막 트랜잭션 시각\n",
    "    if ts_list:\n",
    "        first_ts = min(ts_list)\n",
    "        last_ts = max(ts_list)\n",
    "    else:\n",
    "        first_ts = None\n",
    "        last_ts = None\n",
    "\n",
    "    rows.append({\n",
    "        'address': n,\n",
    "\n",
    "        # 1~4 유일 송/수신 관련\n",
    "        'unique_sender_nodes_count': uniq_send_count,                          # (1)\n",
    "        'unique_receiver_nodes_count': uniq_recv_count,                        # (2)\n",
    "        'unique_sender_total_amount': float(uniq_send_amount),                 # (3)\n",
    "        'unique_receiver_total_amount': float(uniq_recv_amount),               # (4)\n",
    "\n",
    "        # 5~6 순환/양방향\n",
    "        'cycle_tx_count': int(cyc_cnt),                                        # (5)\n",
    "        'bidirectional_counterparties': int(bidi_cnt),                         # (6)\n",
    "\n",
    "        # 7~10 중심성\n",
    "        'closeness_centrality': float(clo_c),                                  # (7)\n",
    "        'betweenness_centrality': float(bet_c),                                # (8)\n",
    "        'pagerank': float(pr),                                                 # (9)\n",
    "        'degree_centrality': float(deg_c),                                     # (10)\n",
    "\n",
    "        # 11~12 이웃수(방향)\n",
    "        'in_neighbor_count': len(in_neigh),                                    # (11)\n",
    "        'out_neighbor_count': len(out_neigh),                                  # (12)\n",
    "\n",
    "        # 13~22 in/out 트랜잭션 집계\n",
    "        'total_in_tx_count': int(total_in_cnt),                                # (13)\n",
    "        'total_out_tx_count': int(total_out_cnt),                              # (14)\n",
    "        'total_in_amount': float(total_in_amt),                                 # (15)\n",
    "        'total_out_amount': float(total_out_amt),                               # (16)\n",
    "        'avg_in_amount': float(avg_in_amt),                                     # (17)\n",
    "        'avg_out_amount': float(avg_out_amt),                                   # (18)\n",
    "        'total_in_gas_used': int(total_in_gas),                                 # (19)\n",
    "        'total_out_gas_used': int(total_out_gas),                               # (20)\n",
    "        'avg_in_gas_used': float(avg_in_gas),                                   # (21)\n",
    "        'avg_out_gas_used': float(avg_out_gas),                                 # (22)\n",
    "\n",
    "        # 23~25 일 단위\n",
    "        'active_days': int(active_days),                                        # (23)\n",
    "        'tx_per_day': float(tx_per_day),                                        # (24)\n",
    "        'amount_per_day': float(amt_per_day),                                   # (25)\n",
    "\n",
    "        # 26~27 가스 효율\n",
    "        'recv_gas_efficiency': float(recv_gas_eff),                             # (26)\n",
    "        'send_gas_efficiency': float(send_gas_eff),                             # (27)\n",
    "\n",
    "        # 28~29 첫/마지막 거래시각 (epoch seconds)\n",
    "        'first_tx_time': int(first_ts) if first_ts is not None else None,       # (28)\n",
    "        'last_tx_time': int(last_ts) if last_ts is not None else None           # (29)\n",
    "    })\n",
    "\n",
    "node_features = pd.DataFrame(rows).sort_values('address').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0826c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: node_features.csv / G_base_multidigraph.pkl / H_summary_graph.pkl 생성\n"
     ]
    }
   ],
   "source": [
    "# 4) 산출물 저장\n",
    "node_features.to_csv('node_features.csv', index=False, encoding='utf-8')\n",
    "\n",
    "import pickle\n",
    "with open(\"G_base_multidigraph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G_base, f)\n",
    "with open(\"H_summary_graph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(H_summary, f)\n",
    "\n",
    "print(\"✅ 완료: node_features.csv / G_base_multidigraph.pkl / H_summary_graph.pkl 생성\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f385290",
   "metadata": {},
   "source": [
    "### Node2vec방식으로 그래프구조만 벡터로 임베딩하여 학습 - GAT알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6219fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu | nodes: 7958 | edges: 25601\n",
      "🛠️ Node2Vec 임베딩을 새로 학습합니다...\n",
      "[Node2Vec] epoch 001 | loss 3.0723\n",
      "[Node2Vec] epoch 002 | loss 1.3729\n",
      "[Node2Vec] epoch 003 | loss 0.9691\n",
      "[Node2Vec] epoch 004 | loss 0.8544\n",
      "[Node2Vec] epoch 005 | loss 0.8131\n",
      "✅ 저장 완료: node2vec_embeddings.npy, edge_index.pt, addresses.csv, node2vec.pt\n",
      "[GAT-AE] epoch 0001 | recon MSE 0.251541\n",
      "[GAT-AE] epoch 0050 | recon MSE 0.093097\n",
      "[GAT-AE] epoch 0100 | recon MSE 0.075579\n",
      "[GAT-AE] epoch 0150 | recon MSE 0.072817\n",
      "[GAT-AE] epoch 0200 | recon MSE 0.073885\n",
      "[GAT-AE] epoch 0250 | recon MSE 0.069703\n",
      "[GAT-AE] epoch 0300 | recon MSE 0.067430\n",
      "[GAT-AE] epoch 0350 | recon MSE 0.066992\n",
      "[GAT-AE] epoch 0400 | recon MSE 0.066373\n",
      "[GAT-AE] epoch 0450 | recon MSE 0.065949\n",
      "[GAT-AE] epoch 0500 | recon MSE 0.066416\n",
      "[GAT-AE] epoch 0550 | recon MSE 0.065492\n",
      "[GAT-AE] epoch 0600 | recon MSE 0.065401\n",
      "[GAT-AE] epoch 0650 | recon MSE 0.065288\n",
      "[GAT-AE] epoch 0700 | recon MSE 0.065069\n",
      "[GAT-AE] epoch 0750 | recon MSE 0.065271\n",
      "[GAT-AE] epoch 0800 | recon MSE 0.065163\n",
      "[GAT-AE] epoch 0850 | recon MSE 0.064657\n",
      "[GAT-AE] epoch 0900 | recon MSE 0.064808\n",
      "[GAT-AE] epoch 0950 | recon MSE 0.065027\n",
      "[GAT-AE] epoch 1000 | recon MSE 0.064793\n",
      "상위 5% z-score 임계값: 1.1053\n",
      "이상치 노드 수: 398 / 7958\n",
      "✅ 완료: gat_ae_anomalies.csv / gat_autoencoder.pt 생성\n",
      "ℹ️ 임베딩/엣지는 파일로 보관됨 → node2vec_embeddings.npy, edge_index.pt, addresses.csv (필요 시 재사용)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Node2Vec(64d; CPU, 저장/재사용) + GAT 오토인코더(256->32->64; DEVICE)\n",
    "→ 재구성오차 z-score → 상위 5% 이상치\n",
    "\n",
    "- Node2Vec은 CPU에서만 수행 (edge_index도 CPU)\n",
    "- DataLoader는 num_workers=0 (Windows/Jupyter PyCapsule 피클링 에러 회피)\n",
    "- 임베딩/엣지/주소를 디스크에 저장하여 다음 세션에서 재사용\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Node2Vec, GATConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 경로/환경\n",
    "NODE_FEAT_CSV = \"node_features.csv\"\n",
    "GRAPH_PKL     = \"G_base_multidigraph.pkl\"\n",
    "\n",
    "EMB_NPY = \"node2vec_embeddings.npy\"  # 저장될 임베딩\n",
    "EDGE_PT = \"edge_index.pt\"            # 저장될 edge_index(CPU long)\n",
    "ADDR_CSV = \"addresses.csv\"           # 저장될 주소 순서\n",
    "N2V_PT  = \"node2vec.pt\"              # (선택) Node2Vec state_dict\n",
    "\n",
    "FORCE_RETRAIN = False  # True로 바꾸면 임베딩을 강제로 다시 학습\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) 노드/그래프 로드\n",
    "if not os.path.exists(NODE_FEAT_CSV):\n",
    "    raise FileNotFoundError(f\"{NODE_FEAT_CSV} 파일이 없습니다.\")\n",
    "if not os.path.exists(GRAPH_PKL):\n",
    "    raise FileNotFoundError(f\"{GRAPH_PKL} 파일이 없습니다.\")\n",
    "\n",
    "node_df = pd.read_csv(NODE_FEAT_CSV)\n",
    "addresses_cur = node_df['address'].astype(str).tolist()\n",
    "addr2idx = {a: i for i, a in enumerate(addresses_cur)}\n",
    "\n",
    "with open(GRAPH_PKL, \"rb\") as f:\n",
    "    G_nx = pickle.load(f)  # networkx.MultiDiGraph\n",
    "\n",
    "# edge_index (CPU 텐서)\n",
    "edges = []\n",
    "for u, v, _k in G_nx.edges(keys=True):\n",
    "    if u in addr2idx and v in addr2idx:\n",
    "        edges.append([addr2idx[u], addr2idx[v]])\n",
    "edge_index_cpu = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2,E] (CPU)\n",
    "\n",
    "num_nodes = len(addresses_cur)\n",
    "num_edges = edge_index_cpu.size(1)\n",
    "print(f\"DEVICE: {DEVICE} | nodes: {num_nodes} | edges: {num_edges}\")\n",
    "\n",
    "# (선택) 양방향 추가: 안정성/성능 향상에 도움\n",
    "# edge_index_cpu = torch.cat([edge_index_cpu, edge_index_cpu.flip(0)], dim=1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Node2Vec 임베딩: 저장본이 있으면 로드, 없으면 학습 후 저장\n",
    "use_saved = (not FORCE_RETRAIN) and os.path.exists(EMB_NPY) and os.path.exists(EDGE_PT) and os.path.exists(ADDR_CSV)\n",
    "\n",
    "def load_saved_embeddings():\n",
    "    # 주소 순서 일치 여부 검증\n",
    "    addresses_saved = pd.read_csv(ADDR_CSV)['address'].astype(str).tolist()\n",
    "    if len(addresses_saved) != len(addresses_cur) or any(a!=b for a,b in zip(addresses_saved, addresses_cur)):\n",
    "        print(\"⚠️ 저장된 addresses.csv 와 현재 addresses 순서/개수가 다릅니다. 재학습으로 전환합니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "    x_np = np.load(EMB_NPY)  # (N,64)\n",
    "    if x_np.shape[0] != len(addresses_cur) or x_np.shape[1] != 64:\n",
    "        print(\"⚠️ 저장된 임베딩 크기가 예상과 다릅니다. 재학습으로 전환합니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "    edge_idx_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n",
    "    # 간단 검증: dtype/shape\n",
    "    if edge_idx_saved.dtype != torch.long or edge_idx_saved.dim()!=2 or edge_idx_saved.size(0)!=2:\n",
    "        print(\"⚠️ 저장된 edge_index 형식이 예상과 다릅니다. 재학습으로 전환합니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"✅ 저장된 Node2Vec 임베딩/엣지/주소를 불러옵니다.\")\n",
    "    return x_np, edge_idx_saved, addresses_saved\n",
    "\n",
    "x_init_cpu = None\n",
    "if use_saved:\n",
    "    x_np, edge_index_loaded, addresses_saved = load_saved_embeddings()\n",
    "    if x_np is not None:\n",
    "        x_init_cpu = torch.tensor(x_np, dtype=torch.float32)  # (N,64) CPU\n",
    "        edge_index_cpu = edge_index_loaded                    # 저장된 엣지로 교체(안전)\n",
    "        addresses = addresses_saved\n",
    "    else:\n",
    "        use_saved = False  # 불일치 -> 재학습\n",
    "\n",
    "if not use_saved:\n",
    "    # Node2Vec (CPU에서만 수행)\n",
    "    print(\"🛠️ Node2Vec 임베딩을 새로 학습합니다...\")\n",
    "    data_cpu = Data(edge_index=edge_index_cpu, num_nodes=num_nodes)  # CPU 전용 Data\n",
    "\n",
    "    n2v = Node2Vec(\n",
    "        data_cpu.edge_index,  # CPU 텐서\n",
    "        embedding_dim=64,\n",
    "        walk_length=30,\n",
    "        context_size=10,     # window\n",
    "        walks_per_node=200,  # num_walk\n",
    "        p=1.0, q=1.0,\n",
    "        num_negative_samples=1,\n",
    "        sparse=True          # SparseAdam 사용\n",
    "    )\n",
    "    n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=0, persistent_workers=False)\n",
    "    n2v_optimizer = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "    def train_node2vec(epochs=5):\n",
    "        n2v.train()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            total_loss = 0.0\n",
    "            for pos_rw, neg_rw in n2v_loader:\n",
    "                n2v_optimizer.zero_grad()\n",
    "                loss = n2v.loss(pos_rw, neg_rw)  # CPU 경로\n",
    "                loss.backward()\n",
    "                n2v_optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f\"[Node2Vec] epoch {epoch:03d} | loss {total_loss/len(n2v_loader):.4f}\")\n",
    "\n",
    "    train_node2vec(epochs=5)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_init_cpu = n2v.embedding.weight.clone().detach()     # (N,64) CPU\n",
    "\n",
    "    # ─ 저장 ─\n",
    "    np.save(EMB_NPY, x_init_cpu.numpy())\n",
    "    torch.save(edge_index_cpu, EDGE_PT)\n",
    "    pd.Series(addresses_cur, name=\"address\").to_csv(ADDR_CSV, index=False)\n",
    "    try:\n",
    "        torch.save(n2v.state_dict(), N2V_PT)\n",
    "    except Exception as e:\n",
    "        print(f\"(참고) Node2Vec state 저장 생략: {e}\")\n",
    "    addresses = addresses_cur\n",
    "    print(f\"✅ 저장 완료: {EMB_NPY}, {EDGE_PT}, {ADDR_CSV}, {N2V_PT}\")\n",
    "\n",
    "# 최종 입력 텐서 (DEVICE로 이동)\n",
    "x_in = x_init_cpu.to(DEVICE)\n",
    "edge_index_dev = edge_index_cpu.to(DEVICE)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) GAT 오토인코더 (DEVICE에서 수행)\n",
    "class GATAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        # 64 -> (32 * 8) = 256\n",
    "        self.gat1 = GATConv(in_channels=in_dim, out_channels=32, heads=8, concat=True, dropout=dropout)\n",
    "        # 256 -> 32\n",
    "        self.gat2 = GATConv(in_channels=256, out_channels=32, heads=1, concat=True, dropout=dropout)\n",
    "        # 32 -> 64\n",
    "        self.gat3 = GATConv(in_channels=32, out_channels=64, heads=1, concat=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat3(x, edge_index)  # 최종 복원 64d\n",
    "        return x\n",
    "\n",
    "model = GATAutoEncoder(in_dim=64, dropout=0.3).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) 학습 (1000 epochs, MSE 재구성오차)\n",
    "def train_gat_ae(epochs=1000):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        x_hat = model(x_in, edge_index_dev)\n",
    "        loss = F.mse_loss(x_hat, x_in)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 50 == 0 or epoch == 1:\n",
    "            print(f\"[GAT-AE] epoch {epoch:04d} | recon MSE {loss.item():.6f}\")\n",
    "\n",
    "train_gat_ae(epochs=1000)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) 재구성오차 → z-score → 상위 5% 이상치\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_recon = model(x_in, edge_index_dev)\n",
    "\n",
    "recon_err = torch.mean((x_recon - x_in) ** 2, dim=1).detach().cpu().numpy()\n",
    "mu = recon_err.mean()\n",
    "sigma = recon_err.std(ddof=1) if recon_err.size > 1 else 1e-8\n",
    "z = (recon_err - mu) / (sigma if sigma > 0 else 1e-8)\n",
    "z_cut = np.percentile(z, 95.0)\n",
    "anom = (z > z_cut).astype(int)\n",
    "\n",
    "print(f\"상위 5% z-score 임계값: {z_cut:.4f}\")\n",
    "print(f\"이상치 노드 수: {anom.sum()} / {len(anom)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) 결과 저장\n",
    "out = pd.DataFrame({\n",
    "    \"address\": addresses,\n",
    "    \"recon_mse\": recon_err,\n",
    "    \"z_score\": z,\n",
    "    \"is_anomaly_top5pct\": anom\n",
    "})\n",
    "out.sort_values(\"z_score\", ascending=False).to_csv(\"gat_ae_anomalies.csv\", index=False, encoding=\"utf-8\")\n",
    "torch.save(model.state_dict(), \"gat_autoencoder.pt\")\n",
    "\n",
    "print(\"✅ 완료: gat_ae_anomalies.csv / gat_autoencoder.pt 생성\")\n",
    "print(f\"ℹ️ 임베딩/엣지는 파일로 보관됨 → {EMB_NPY}, {EDGE_PT}, {ADDR_CSV} (필요 시 재사용)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744e0fd",
   "metadata": {},
   "source": [
    "### Node2vec방식으로 그래프구조만 벡터로 임베딩하여 학습 - GraphSAGE알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27561c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu | nodes: 7958 | edges: 25601\n",
      "✅ 저장된 Node2Vec 임베딩/엣지/주소를 불러옵니다.\n",
      "[SAGE-AE] epoch 0001 | recon MSE 0.250588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_30980\\1176852788.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_idx_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAGE-AE] epoch 0050 | recon MSE 0.130431\n",
      "[SAGE-AE] epoch 0100 | recon MSE 0.090441\n",
      "[SAGE-AE] epoch 0150 | recon MSE 0.085147\n",
      "[SAGE-AE] epoch 0200 | recon MSE 0.074807\n",
      "[SAGE-AE] epoch 0250 | recon MSE 0.068855\n",
      "[SAGE-AE] epoch 0300 | recon MSE 0.067581\n",
      "[SAGE-AE] epoch 0350 | recon MSE 0.067303\n",
      "[SAGE-AE] epoch 0400 | recon MSE 0.064358\n",
      "[SAGE-AE] epoch 0450 | recon MSE 0.063148\n",
      "[SAGE-AE] epoch 0500 | recon MSE 0.063130\n",
      "[SAGE-AE] epoch 0550 | recon MSE 0.062990\n",
      "[SAGE-AE] epoch 0600 | recon MSE 0.062119\n",
      "[SAGE-AE] epoch 0650 | recon MSE 0.061254\n",
      "[SAGE-AE] epoch 0700 | recon MSE 0.060762\n",
      "[SAGE-AE] epoch 0750 | recon MSE 0.060542\n",
      "[SAGE-AE] epoch 0800 | recon MSE 0.061159\n",
      "[SAGE-AE] epoch 0850 | recon MSE 0.059888\n",
      "[SAGE-AE] epoch 0900 | recon MSE 0.059822\n",
      "[SAGE-AE] epoch 0950 | recon MSE 0.059361\n",
      "[SAGE-AE] epoch 1000 | recon MSE 0.059117\n",
      "상위 5% z-score 임계값: 1.1954\n",
      "이상치 노드 수: 398 / 7958\n",
      "✅ 완료: sage_ae_anomalies.csv / sage_autoencoder.pt 생성\n",
      "ℹ️ 임베딩/엣지는 파일로 보관됨 → node2vec_embeddings.npy, edge_index.pt, addresses.csv (필요 시 재사용)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Node2Vec(64d; CPU, 저장/재사용) + GraphSAGE 오토인코더(256->32->64; DEVICE)\n",
    "→ 재구성오차 z-score → 상위 5% 이상치\n",
    "\n",
    "- Node2Vec은 CPU에서만 수행 (edge_index도 CPU)\n",
    "- DataLoader num_workers=0 (Windows/Jupyter PyCapsule 피클링 에러 회피)\n",
    "- 임베딩/엣지/주소를 디스크에 저장하여 다음 세션에서 재사용\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Node2Vec, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 경로/환경\n",
    "NODE_FEAT_CSV = \"node_features.csv\"\n",
    "GRAPH_PKL     = \"G_base_multidigraph.pkl\"\n",
    "\n",
    "# Node2Vec 산출물 (GAT 스크립트와 공유 가능)\n",
    "EMB_NPY  = \"node2vec_embeddings.npy\"  # 저장될 임베딩 (N,64)\n",
    "EDGE_PT  = \"edge_index.pt\"            # 저장될 edge_index (CPU long)\n",
    "ADDR_CSV = \"addresses.csv\"            # 저장될 주소 순서\n",
    "N2V_PT   = \"node2vec.pt\"              # (선택) Node2Vec state_dict\n",
    "\n",
    "FORCE_RETRAIN = False  # True면 Node2Vec을 강제로 다시 학습\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) 노드/그래프 로드\n",
    "if not os.path.exists(NODE_FEAT_CSV):\n",
    "    raise FileNotFoundError(f\"{NODE_FEAT_CSV} 파일이 없습니다.\")\n",
    "if not os.path.exists(GRAPH_PKL):\n",
    "    raise FileNotFoundError(f\"{GRAPH_PKL} 파일이 없습니다.\")\n",
    "\n",
    "node_df = pd.read_csv(NODE_FEAT_CSV)\n",
    "addresses_cur = node_df['address'].astype(str).tolist()\n",
    "addr2idx = {a: i for i, a in enumerate(addresses_cur)}\n",
    "\n",
    "with open(GRAPH_PKL, \"rb\") as f:\n",
    "    G_nx = pickle.load(f)  # networkx.MultiDiGraph\n",
    "\n",
    "# edge_index (CPU 텐서)\n",
    "edges = []\n",
    "for u, v, _k in G_nx.edges(keys=True):\n",
    "    if u in addr2idx and v in addr2idx:\n",
    "        edges.append([addr2idx[u], addr2idx[v]])\n",
    "edge_index_cpu = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2,E] (CPU)\n",
    "\n",
    "num_nodes = len(addresses_cur)\n",
    "num_edges = edge_index_cpu.size(1)\n",
    "print(f\"DEVICE: {DEVICE} | nodes: {num_nodes} | edges: {num_edges}\")\n",
    "\n",
    "# (선택) 무방향 효과 추가\n",
    "# edge_index_cpu = torch.cat([edge_index_cpu, edge_index_cpu.flip(0)], dim=1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Node2Vec 임베딩: 저장본이 있으면 로드, 없으면 학습 후 저장\n",
    "use_saved = (not FORCE_RETRAIN) and os.path.exists(EMB_NPY) and os.path.exists(EDGE_PT) and os.path.exists(ADDR_CSV)\n",
    "\n",
    "def load_saved_embeddings():\n",
    "    addresses_saved = pd.read_csv(ADDR_CSV)['address'].astype(str).tolist()\n",
    "    if len(addresses_saved) != len(addresses_cur) or any(a!=b for a,b in zip(addresses_saved, addresses_cur)):\n",
    "        print(\"⚠️ 저장된 addresses.csv 와 현재 addresses 순서/개수가 다릅니다. 재학습으로 전환합니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "    x_np = np.load(EMB_NPY)  # (N,64)\n",
    "    if x_np.shape != (len(addresses_cur), 64):\n",
    "        print(\"⚠️ 저장된 임베딩 크기가 예상과 다릅니다. 재학습으로 전환합니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "    edge_idx_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n",
    "    if edge_idx_saved.dtype != torch.long or edge_idx_saved.dim()!=2 or edge_idx_saved.size(0)!=2:\n",
    "        print(\"⚠️ 저장된 edge_index 형식이 예상과 다릅니다. 재학습으로 전환합니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"✅ 저장된 Node2Vec 임베딩/엣지/주소를 불러옵니다.\")\n",
    "    return x_np, edge_idx_saved, addresses_saved\n",
    "\n",
    "x_init_cpu = None\n",
    "if use_saved:\n",
    "    x_np, edge_index_loaded, addresses_saved = load_saved_embeddings()\n",
    "    if x_np is not None:\n",
    "        x_init_cpu = torch.tensor(x_np, dtype=torch.float32)  # (N,64) CPU\n",
    "        edge_index_cpu = edge_index_loaded\n",
    "        addresses = addresses_saved\n",
    "    else:\n",
    "        use_saved = False\n",
    "\n",
    "if not use_saved:\n",
    "    print(\"🛠️ Node2Vec 임베딩을 새로 학습합니다...\")\n",
    "    data_cpu = Data(edge_index=edge_index_cpu, num_nodes=num_nodes)\n",
    "\n",
    "    n2v = Node2Vec(\n",
    "        data_cpu.edge_index,\n",
    "        embedding_dim=64,\n",
    "        walk_length=30,\n",
    "        context_size=10,     # window\n",
    "        walks_per_node=200,  # num_walk\n",
    "        p=1.0, q=1.0,\n",
    "        num_negative_samples=1,\n",
    "        sparse=True\n",
    "    )\n",
    "    n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=0, persistent_workers=False)\n",
    "    n2v_optimizer = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "    def train_node2vec(epochs=5):\n",
    "        n2v.train()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            total_loss = 0.0\n",
    "            for pos_rw, neg_rw in n2v_loader:\n",
    "                n2v_optimizer.zero_grad()\n",
    "                loss = n2v.loss(pos_rw, neg_rw)\n",
    "                loss.backward()\n",
    "                n2v_optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f\"[Node2Vec] epoch {epoch:03d} | loss {total_loss/len(n2v_loader):.4f}\")\n",
    "\n",
    "    train_node2vec(epochs=5)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_init_cpu = n2v.embedding.weight.clone().detach()  # (N,64) CPU\n",
    "\n",
    "    # 저장\n",
    "    np.save(EMB_NPY, x_init_cpu.numpy())\n",
    "    torch.save(edge_index_cpu, EDGE_PT)\n",
    "    pd.Series(addresses_cur, name=\"address\").to_csv(ADDR_CSV, index=False)\n",
    "    try:\n",
    "        torch.save(n2v.state_dict(), N2V_PT)\n",
    "    except Exception as e:\n",
    "        print(f\"(참고) Node2Vec state 저장 생략: {e}\")\n",
    "    addresses = addresses_cur\n",
    "    print(f\"✅ 저장 완료: {EMB_NPY}, {EDGE_PT}, {ADDR_CSV}, {N2V_PT}\")\n",
    "\n",
    "# 최종 입력/엣지 (DEVICE로 이동)\n",
    "x_in = x_init_cpu.to(DEVICE)          # (N,64)\n",
    "edge_index_dev = edge_index_cpu.to(DEVICE)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) GraphSAGE 오토인코더 (DEVICE에서 수행)\n",
    "class SAGEAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3, aggr=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.s1 = SAGEConv(in_dim, 256, aggr=aggr)  # 64 -> 256\n",
    "        self.s2 = SAGEConv(256, 32, aggr=aggr)      # 256 -> 32\n",
    "        self.s3 = SAGEConv(32, 64, aggr=aggr)       # 32 -> 64\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training); x = F.elu(self.s1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training); x = F.elu(self.s2(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training); x = self.s3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = SAGEAutoEncoder(in_dim=64, dropout=0.3, aggr=\"mean\").to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) 학습 (1000 epochs, MSE 재구성오차)\n",
    "def train_sage_ae(epochs=1000):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        x_hat = model(x_in, edge_index_dev)\n",
    "        loss = F.mse_loss(x_hat, x_in)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 50 == 0 or epoch == 1:\n",
    "            print(f\"[SAGE-AE] epoch {epoch:04d} | recon MSE {loss.item():.6f}\")\n",
    "\n",
    "train_sage_ae(epochs=1000)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) 재구성오차 → z-score → 상위 5% 이상치\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_recon = model(x_in, edge_index_dev)\n",
    "\n",
    "recon_err = torch.mean((x_recon - x_in) ** 2, dim=1).detach().cpu().numpy()\n",
    "mu = recon_err.mean()\n",
    "sigma = recon_err.std(ddof=1) if recon_err.size > 1 else 1e-8\n",
    "z = (recon_err - mu) / (sigma if sigma > 0 else 1e-8)\n",
    "z_cut = np.percentile(z, 95.0)\n",
    "anom = (z > z_cut).astype(int)\n",
    "\n",
    "print(f\"상위 5% z-score 임계값: {z_cut:.4f}\")\n",
    "print(f\"이상치 노드 수: {anom.sum()} / {len(anom)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) 결과 저장 (SAGE 파일명)\n",
    "out = pd.DataFrame({\n",
    "    \"address\": addresses,\n",
    "    \"recon_mse\": recon_err,\n",
    "    \"z_score\": z,\n",
    "    \"is_anomaly_top5pct\": anom\n",
    "})\n",
    "out.sort_values(\"z_score\", ascending=False).to_csv(\"sage_ae_anomalies.csv\", index=False, encoding=\"utf-8\")\n",
    "torch.save(model.state_dict(), \"sage_autoencoder.pt\")\n",
    "\n",
    "print(\"✅ 완료: sage_ae_anomalies.csv / sage_autoencoder.pt 생성\")\n",
    "print(f\"ℹ️ 임베딩/엣지는 파일로 보관됨 → {EMB_NPY}, {EDGE_PT}, {ADDR_CSV} (필요 시 재사용)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8569784",
   "metadata": {},
   "source": [
    "### Node2vec으로 그래프구조임베딩값과 29개의 node피쳐를 결합한 64차원의 그래프임베딩벡터 생성후 GAT,GraphSGAE알고리즘 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1163f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu | nodes: 7958 | edges: 25601\n",
      "✅ 저장된 Node2Vec 임베딩/엣지/주소 사용\n",
      "✅ 결합 임베딩 저장: combined_embeddings_64.npy\n",
      "[GAT_GAE] 0001 | loss 505.491791 | mse 108.071953 | bce 794.839661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_30980\\3738493665.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GAT_GAE] 0050 | loss 8.589891 | mse 2.541967 | bce 12.095848\n",
      "[GAT_GAE] 0100 | loss 3.123414 | mse 1.463450 | bce 3.319929\n",
      "[GAT_GAE] 0150 | loss 2.923254 | mse 1.345032 | bce 3.156443\n",
      "[GAT_GAE] 0200 | loss 2.850860 | mse 1.092607 | bce 3.516506\n",
      "[GAT_GAE] 0250 | loss 3.365918 | mse 1.056040 | bce 4.619755\n",
      "[GAT_GAE] 0300 | loss 2.799266 | mse 1.162821 | bce 3.272889\n",
      "[GAT_GAE] 0350 | loss 2.319847 | mse 1.054340 | bce 2.531014\n",
      "[GAT_GAE] 0400 | loss 2.057616 | mse 0.873196 | bce 2.368840\n",
      "[GAT_GAE] 0450 | loss 1.591910 | mse 0.789524 | bce 1.604770\n",
      "[GAT_GAE] 0500 | loss 1.530125 | mse 0.826689 | bce 1.406873\n",
      "[GAT_GAE] 0550 | loss 1.718401 | mse 0.818809 | bce 1.799184\n",
      "[GAT_GAE] 0600 | loss 1.560501 | mse 0.835535 | bce 1.449933\n",
      "[GAT_GAE] 0650 | loss 1.142637 | mse 0.689243 | bce 0.906788\n",
      "[GAT_GAE] 0700 | loss 1.374990 | mse 0.669408 | bce 1.411165\n",
      "[GAT_GAE] 0750 | loss 1.072892 | mse 0.648325 | bce 0.849134\n",
      "[GAT_GAE] 0800 | loss 0.996120 | mse 0.624989 | bce 0.742264\n",
      "[GAT_GAE] 0850 | loss 0.996045 | mse 0.628552 | bce 0.734985\n",
      "[GAT_GAE] 0900 | loss 1.202295 | mse 0.673077 | bce 1.058435\n",
      "[GAT_GAE] 0950 | loss 1.273426 | mse 0.780418 | bce 0.986016\n",
      "[GAT_GAE] 1000 | loss 1.091685 | mse 0.686920 | bce 0.809529\n",
      "✅ GAT_GAE: 저장 완료 → gat_gae_anomalies.csv, gat_gae_model.pt\n",
      "[SAGE_GAE] 0001 | loss 255.322708 | mse 39.495514 | bce 431.654388\n",
      "[SAGE_GAE] 0050 | loss 8.867414 | mse 1.441756 | bce 14.851318\n",
      "[SAGE_GAE] 0100 | loss 8.019615 | mse 1.056638 | bce 13.925954\n",
      "[SAGE_GAE] 0150 | loss 5.502591 | mse 1.105912 | bce 8.793358\n",
      "[SAGE_GAE] 0200 | loss 6.488220 | mse 0.896375 | bce 11.183689\n",
      "[SAGE_GAE] 0250 | loss 6.650354 | mse 0.752015 | bce 11.796677\n",
      "[SAGE_GAE] 0300 | loss 5.775049 | mse 0.840772 | bce 9.868554\n",
      "[SAGE_GAE] 0350 | loss 5.320173 | mse 0.976250 | bce 8.687847\n",
      "[SAGE_GAE] 0400 | loss 5.236507 | mse 0.836794 | bce 8.799427\n",
      "[SAGE_GAE] 0450 | loss 5.533633 | mse 0.749355 | bce 9.568556\n",
      "[SAGE_GAE] 0500 | loss 5.488731 | mse 0.755069 | bce 9.467324\n",
      "[SAGE_GAE] 0550 | loss 5.415032 | mse 0.682198 | bce 9.465669\n",
      "[SAGE_GAE] 0600 | loss 4.633676 | mse 0.650568 | bce 7.966217\n",
      "[SAGE_GAE] 0650 | loss 5.511638 | mse 0.723205 | bce 9.576865\n",
      "[SAGE_GAE] 0700 | loss 4.521228 | mse 0.620664 | bce 7.801126\n",
      "[SAGE_GAE] 0750 | loss 4.645301 | mse 0.646136 | bce 7.998332\n",
      "[SAGE_GAE] 0800 | loss 3.461331 | mse 0.623467 | bce 5.675729\n",
      "[SAGE_GAE] 0850 | loss 4.506032 | mse 0.609955 | bce 7.792155\n",
      "[SAGE_GAE] 0900 | loss 4.702666 | mse 0.638586 | bce 8.128160\n",
      "[SAGE_GAE] 0950 | loss 3.855585 | mse 0.589831 | bce 6.531508\n",
      "[SAGE_GAE] 1000 | loss 3.825163 | mse 0.587440 | bce 6.475447\n",
      "✅ SAGE_GAE: 저장 완료 → sage_gae_anomalies.csv, sage_gae_model.pt\n",
      "✅ 완료: combined_embeddings_64.npy / scaler.joblib / pca64.joblib 저장\n",
      "ℹ️ GAT_GAE → gat_gae_anomalies.csv, SAGE_GAE → sage_gae_anomalies.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Node2Vec(64, 저장/재사용) + 29속성 결합 → 64차원 입력 생성(PCA)\n",
    "→ GAT-GAE & SAGE-GAE 모두 학습\n",
    "- 특징 재구성(MSE) + 링크 재구성(BCE) 동시 학습\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Node2Vec, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import dump, load\n",
    "\n",
    "# ----------------------------- 설정 ------------------------------\n",
    "NODE_FEAT_CSV = \"node_features.csv\"\n",
    "GRAPH_PKL     = \"G_base_multidigraph.pkl\"\n",
    "\n",
    "# Node2Vec 산출물\n",
    "EMB_NPY  = \"node2vec_embeddings.npy\"\n",
    "EDGE_PT  = \"edge_index.pt\"\n",
    "ADDR_CSV = \"addresses.csv\"\n",
    "N2V_PT   = \"node2vec.pt\"\n",
    "\n",
    "# 결합 임베딩/전처리 저장\n",
    "COMB_EMB_NPY = \"combined_embeddings_64.npy\"\n",
    "SCALER_P     = \"scaler.joblib\"\n",
    "PCA64_P      = \"pca64.joblib\"\n",
    "\n",
    "FORCE_RETRAIN_N2V = False      # True면 Node2Vec 재학습 강제\n",
    "LAMBDA_BCE        = 0.5        # 총손실 = MSE + λ*BCE\n",
    "EPOCHS            = 1000\n",
    "DROPOUT           = 0.3\n",
    "LR                = 1e-3\n",
    "WEIGHT_DECAY      = 5e-4\n",
    "SEED              = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ---------------------- 0) 주소/그래프 로드 -----------------------\n",
    "if not os.path.exists(NODE_FEAT_CSV):\n",
    "    raise FileNotFoundError(f\"{NODE_FEAT_CSV} 없음\")\n",
    "if not os.path.exists(GRAPH_PKL):\n",
    "    raise FileNotFoundError(f\"{GRAPH_PKL} 없음\")\n",
    "\n",
    "node_df = pd.read_csv(NODE_FEAT_CSV)\n",
    "addresses_cur = node_df['address'].astype(str).tolist()\n",
    "addr2idx = {a: i for i,a in enumerate(addresses_cur)}\n",
    "\n",
    "with open(GRAPH_PKL, \"rb\") as f:\n",
    "    import networkx as nx\n",
    "    G_nx = pickle.load(f)  # MultiDiGraph\n",
    "\n",
    "# edge_index (CPU)\n",
    "edges = []\n",
    "for u, v, _k in G_nx.edges(keys=True):\n",
    "    if u in addr2idx and v in addr2idx:\n",
    "        edges.append([addr2idx[u], addr2idx[v]])\n",
    "edge_index_cpu = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "num_nodes = len(addresses_cur)\n",
    "print(f\"DEVICE: {DEVICE} | nodes: {num_nodes} | edges: {edge_index_cpu.size(1)}\")\n",
    "\n",
    "# (선택) 양방향 추가\n",
    "# edge_index_cpu = torch.cat([edge_index_cpu, edge_index_cpu.flip(0)], dim=1)\n",
    "\n",
    "# ---------------------- 1) Node2Vec 로드/학습 ----------------------\n",
    "def try_load_saved_n2v():\n",
    "    if not (os.path.exists(EMB_NPY) and os.path.exists(EDGE_PT) and os.path.exists(ADDR_CSV)):\n",
    "        return None\n",
    "    addr_saved = pd.read_csv(ADDR_CSV)['address'].astype(str).tolist()\n",
    "    if len(addr_saved)!=len(addresses_cur) or any(a!=b for a,b in zip(addr_saved, addresses_cur)):\n",
    "        print(\"⚠️ 저장된 addresses와 현재가 불일치 → N2V 재학습\")\n",
    "        return None\n",
    "    x_np = np.load(EMB_NPY)\n",
    "    if x_np.shape!=(len(addresses_cur), 64):\n",
    "        print(\"⚠️ 저장된 임베딩 크기 불일치 → N2V 재학습\")\n",
    "        return None\n",
    "    edge_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n",
    "    if edge_saved.dtype!=torch.long or edge_saved.dim()!=2 or edge_saved.size(0)!=2:\n",
    "        print(\"⚠️ 저장된 edge_index 형식 이상 → N2V 재학습\")\n",
    "        return None\n",
    "    print(\"✅ 저장된 Node2Vec 임베딩/엣지/주소 사용\")\n",
    "    return torch.tensor(x_np, dtype=torch.float32), edge_saved, addr_saved\n",
    "\n",
    "x_n2v_cpu = None\n",
    "if not FORCE_RETRAIN_N2V:\n",
    "    loaded = try_load_saved_n2v()\n",
    "    if loaded:\n",
    "        x_n2v_cpu, edge_index_cpu, addresses = loaded\n",
    "\n",
    "if x_n2v_cpu is None:\n",
    "    print(\"🛠️ Node2Vec를 새로 학습합니다...\")\n",
    "    data_cpu = Data(edge_index=edge_index_cpu, num_nodes=num_nodes)\n",
    "    n2v = Node2Vec(\n",
    "        data_cpu.edge_index, embedding_dim=64,\n",
    "        walk_length=30, context_size=10, walks_per_node=200,\n",
    "        p=1.0, q=1.0, num_negative_samples=1, sparse=True\n",
    "    )\n",
    "    n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=0, persistent_workers=False)\n",
    "    n2v_opt = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "    def train_n2v(epochs=5):\n",
    "        n2v.train()\n",
    "        for ep in range(1, epochs+1):\n",
    "            tot=0.0\n",
    "            for pos_rw, neg_rw in n2v_loader:\n",
    "                n2v_opt.zero_grad()\n",
    "                loss = n2v.loss(pos_rw, neg_rw)\n",
    "                loss.backward(); n2v_opt.step()\n",
    "                tot += loss.item()\n",
    "            print(f\"[Node2Vec] epoch {ep:03d} | loss {tot/len(n2v_loader):.4f}\")\n",
    "\n",
    "    train_n2v(epochs=5)\n",
    "    with torch.no_grad():\n",
    "        x_n2v_cpu = n2v.embedding.weight.clone().detach()   # (N,64)\n",
    "    # 저장\n",
    "    np.save(EMB_NPY, x_n2v_cpu.numpy())\n",
    "    torch.save(edge_index_cpu, EDGE_PT)\n",
    "    pd.Series(addresses_cur, name=\"address\").to_csv(ADDR_CSV, index=False)\n",
    "    try: torch.save(n2v.state_dict(), N2V_PT)\n",
    "    except Exception as e: print(f\"(참고) Node2Vec state 저장 생략: {e}\")\n",
    "    addresses = addresses_cur\n",
    "    print(\"✅ Node2Vec 저장 완료\")\n",
    "\n",
    "# ---------------- 2) 29속성과 결합 → 64차 투영(PCA) ----------------\n",
    "node = pd.read_csv(NODE_FEAT_CSV).set_index(\"address\")\n",
    "feat_cols = [c for c in node.columns]  # 주소 제외 29개\n",
    "X_attr = node.reindex(addresses)[feat_cols].replace([np.inf,-np.inf], np.nan).fillna(0).astype(float).values  # (N,29)\n",
    "\n",
    "# 표준화\n",
    "if os.path.exists(SCALER_P) and os.path.exists(PCA64_P):\n",
    "    try:\n",
    "        scaler = load(SCALER_P); pca64 = load(PCA64_P)\n",
    "        print(\"✅ 저장된 Scaler/PCA 로드\")\n",
    "    except Exception:\n",
    "        scaler = StandardScaler().fit(X_attr)\n",
    "        pca64  = PCA(n_components=64, random_state=SEED).fit(np.hstack([x_n2v_cpu.numpy(), scaler.transform(X_attr)]))\n",
    "        dump(scaler, SCALER_P); dump(pca64, PCA64_P)\n",
    "else:\n",
    "    scaler = StandardScaler().fit(X_attr)\n",
    "    dump(scaler, SCALER_P)\n",
    "    # concat(64+29=93) → PCA 64\n",
    "    X_concat_fit = np.hstack([x_n2v_cpu.numpy(), scaler.transform(X_attr)])\n",
    "    pca64 = PCA(n_components=64, random_state=SEED).fit(X_concat_fit)\n",
    "    dump(pca64, PCA64_P)\n",
    "\n",
    "X_concat = np.hstack([x_n2v_cpu.numpy(), scaler.transform(X_attr)])   # (N,93)\n",
    "X64 = pca64.transform(X_concat).astype(np.float32)                     # (N,64)\n",
    "np.save(COMB_EMB_NPY, X64)\n",
    "print(\"✅ 결합 임베딩 저장:\", COMB_EMB_NPY)\n",
    "\n",
    "x_in = torch.tensor(X64, dtype=torch.float32, device=DEVICE)\n",
    "edge_index_dev = edge_index_cpu.to(DEVICE)\n",
    "\n",
    "# ----------------------- 3) 모델 정의 ------------------------\n",
    "class GAT_GAE(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.do = dropout\n",
    "        self.g1 = GATConv(in_dim, 32, heads=8, concat=True, dropout=dropout)  # 64 -> 256\n",
    "        self.g2 = GATConv(256, 32, heads=1, concat=True, dropout=dropout)     # 256 -> 32 (z)\n",
    "        self.g3 = GATConv(32, 64, heads=1, concat=True, dropout=dropout)      # 32 -> 64 (x_hat)\n",
    "    def forward(self, x, ei):\n",
    "        x = F.dropout(x, p=self.do, training=self.training); x = F.elu(self.g1(x, ei))\n",
    "        x = F.dropout(x, p=self.do, training=self.training); z = F.elu(self.g2(x, ei))\n",
    "        x_hat = F.dropout(z, p=self.do, training=self.training); x_hat = self.g3(x_hat, ei)\n",
    "        return x_hat, z\n",
    "\n",
    "class SAGE_GAE(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3, aggr=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.do = dropout\n",
    "        self.s1 = SAGEConv(in_dim, 256, aggr=aggr)\n",
    "        self.s2 = SAGEConv(256, 32, aggr=aggr)   # z\n",
    "        self.s3 = SAGEConv(32, 64, aggr=aggr)    # x_hat\n",
    "    def forward(self, x, ei):\n",
    "        x = F.dropout(x, p=self.do, training=self.training); x = F.elu(self.s1(x, ei))\n",
    "        z = F.dropout(x, p=self.do, training=self.training); z = F.elu(self.s2(z, ei))\n",
    "        x_hat = F.dropout(z, p=self.do, training=self.training); x_hat = self.s3(x_hat, ei)\n",
    "        return x_hat, z\n",
    "\n",
    "def link_bce_loss(z, edge_index, num_neg=None):\n",
    "    # pos/neg 샘플\n",
    "    pos = edge_index\n",
    "    if num_neg is None: num_neg = pos.size(1)\n",
    "    neg = negative_sampling(pos, num_nodes=z.size(0), num_neg_samples=num_neg, method='sparse')\n",
    "    # dot decode\n",
    "    def dot_decode(z, e): return (z[e[0]] * z[e[1]]).sum(dim=1)\n",
    "    logits = torch.cat([dot_decode(z, pos), dot_decode(z, neg)], dim=0)\n",
    "    labels = torch.cat([\n",
    "        torch.ones(pos.size(1), device=logits.device),\n",
    "        torch.zeros(neg.size(1), device=logits.device)\n",
    "    ], dim=0)\n",
    "    return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "def train_gae(model, epochs, name):\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); opt.zero_grad()\n",
    "        x_hat, z = model(x_in, edge_index_dev)\n",
    "        mse = F.mse_loss(x_hat, x_in)\n",
    "        bce = link_bce_loss(z, edge_index_dev)\n",
    "        loss = mse + LAMBDA_BCE * bce\n",
    "        loss.backward(); opt.step()\n",
    "        if ep==1 or ep%50==0:\n",
    "            print(f\"[{name}] {ep:04d} | loss {loss.item():.6f} | mse {mse.item():.6f} | bce {bce.item():.6f}\")\n",
    "    # 평가/저장\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_hat, z = model(x_in, edge_index_dev)\n",
    "    recon = torch.mean((x_hat - x_in)**2, dim=1).detach().cpu().numpy()\n",
    "    mu, sd = recon.mean(), recon.std(ddof=1) if recon.size>1 else 1e-8\n",
    "    zscore = (recon - mu) / (sd if sd>0 else 1e-8)\n",
    "    cut = np.percentile(zscore, 95.0)\n",
    "    anom = (zscore > cut).astype(int)\n",
    "\n",
    "    out = pd.DataFrame({\"address\": addresses, \"recon_mse\": recon, \"z_score\": zscore, \"is_anomaly_top5pct\": anom})\n",
    "    csv_name = f\"{name.lower()}_anomalies.csv\"\n",
    "    pt_name  = f\"{name.lower()}_model.pt\"\n",
    "    out.sort_values(\"z_score\", ascending=False).to_csv(csv_name, index=False, encoding=\"utf-8\")\n",
    "    torch.save(model.state_dict(), pt_name)\n",
    "    print(f\"✅ {name}: 저장 완료 → {csv_name}, {pt_name}\")\n",
    "    return out\n",
    "\n",
    "# -------------------- 4) 두 모델 연속 실행 --------------------\n",
    "gat_out  = train_gae(GAT_GAE(in_dim=64, dropout=DROPOUT),  EPOCHS, \"GAT_GAE\")\n",
    "sage_out = train_gae(SAGE_GAE(in_dim=64, dropout=DROPOUT), EPOCHS, \"SAGE_GAE\")\n",
    "\n",
    "print(\"✅ 완료: combined_embeddings_64.npy / scaler.joblib / pca64.joblib 저장\")\n",
    "print(\"ℹ️ GAT_GAE → gat_gae_anomalies.csv, SAGE_GAE → sage_gae_anomalies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972d63b",
   "metadata": {},
   "source": [
    "### GAT,GraphSAGE 모두 미니배치방식으로 학습한 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d3b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu | nodes: 7958 | edges: 25601\n",
      "✅ 저장된 Node2Vec 임베딩/엣지/주소 사용\n",
      "✅ 저장된 Scaler/PCA 로드\n",
      "✅ 결합 임베딩 저장: combined_embeddings_64.npy\n",
      "[GAT_GAE] 0001 | loss 242.304894 | mse 71.805924 | bce 340.997938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_30980\\3282253683.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GAT_GAE] 0050 | loss 3.195619 | mse 1.206307 | bce 3.978624\n",
      "[GAT_GAE] 0100 | loss 1.972099 | mse 0.952752 | bce 2.038694\n",
      "[GAT_GAE] 0150 | loss 1.109245 | mse 0.702397 | bce 0.813695\n",
      "[GAT_GAE] 0200 | loss 1.006012 | mse 0.599225 | bce 0.813574\n",
      "[GAT_GAE] 0250 | loss 0.981288 | mse 0.597751 | bce 0.767074\n",
      "[GAT_GAE] 0300 | loss 0.906257 | mse 0.566926 | bce 0.678661\n",
      "[GAT_GAE] 0350 | loss 1.046467 | mse 0.609092 | bce 0.874750\n",
      "[GAT_GAE] 0400 | loss 0.929497 | mse 0.557273 | bce 0.744447\n",
      "[GAT_GAE] 0450 | loss 0.822681 | mse 0.518042 | bce 0.609278\n",
      "[GAT_GAE] 0500 | loss 0.849261 | mse 0.536495 | bce 0.625531\n",
      "[GAT_GAE] 0550 | loss 0.861889 | mse 0.521575 | bce 0.680628\n",
      "[GAT_GAE] 0600 | loss 0.815565 | mse 0.507944 | bce 0.615243\n",
      "[GAT_GAE] 0650 | loss 0.958153 | mse 0.503514 | bce 0.909279\n",
      "[GAT_GAE] 0700 | loss 0.803176 | mse 0.501523 | bce 0.603306\n",
      "[GAT_GAE] 0750 | loss 0.752475 | mse 0.491933 | bce 0.521083\n",
      "[GAT_GAE] 0800 | loss 0.788474 | mse 0.473126 | bce 0.630697\n",
      "[GAT_GAE] 0850 | loss 0.777943 | mse 0.475340 | bce 0.605208\n",
      "[GAT_GAE] 0900 | loss 0.805074 | mse 0.484082 | bce 0.641983\n",
      "[GAT_GAE] 0950 | loss 0.816129 | mse 0.506631 | bce 0.618996\n",
      "[GAT_GAE] 1000 | loss 0.830228 | mse 0.505723 | bce 0.649010\n",
      "✅ GAT_GAE (mini-batch): 저장 완료 → gat_gae_mb_anomalies.csv, gat_gae_mb_model.pt\n",
      "[SAGE_GAE] 0001 | loss 103.659994 | mse 15.968233 | bce 175.383526\n",
      "[SAGE_GAE] 0050 | loss 6.287239 | mse 0.846734 | bce 10.881010\n",
      "[SAGE_GAE] 0100 | loss 5.351128 | mse 0.612473 | bce 9.477309\n",
      "[SAGE_GAE] 0150 | loss 4.532990 | mse 0.556760 | bce 7.952461\n",
      "[SAGE_GAE] 0200 | loss 3.936536 | mse 0.515066 | bce 6.842940\n",
      "[SAGE_GAE] 0250 | loss 2.777448 | mse 0.487692 | bce 4.579512\n",
      "[SAGE_GAE] 0300 | loss 2.548775 | mse 0.488837 | bce 4.119875\n",
      "[SAGE_GAE] 0350 | loss 1.542613 | mse 0.462057 | bce 2.161113\n",
      "[SAGE_GAE] 0400 | loss 1.283896 | mse 0.455370 | bce 1.657052\n",
      "[SAGE_GAE] 0450 | loss 1.098740 | mse 0.453026 | bce 1.291429\n",
      "[SAGE_GAE] 0500 | loss 0.940331 | mse 0.433482 | bce 1.013699\n",
      "[SAGE_GAE] 0550 | loss 0.811859 | mse 0.416819 | bce 0.790080\n",
      "[SAGE_GAE] 0600 | loss 0.696285 | mse 0.389331 | bce 0.613907\n",
      "[SAGE_GAE] 0650 | loss 0.758409 | mse 0.393461 | bce 0.729895\n",
      "[SAGE_GAE] 0700 | loss 0.864901 | mse 0.407849 | bce 0.914104\n",
      "[SAGE_GAE] 0750 | loss 0.756307 | mse 0.403195 | bce 0.706225\n",
      "[SAGE_GAE] 0800 | loss 0.808774 | mse 0.391013 | bce 0.835523\n",
      "[SAGE_GAE] 0850 | loss 0.796843 | mse 0.433482 | bce 0.726723\n",
      "[SAGE_GAE] 0900 | loss 0.846595 | mse 0.395303 | bce 0.902584\n",
      "[SAGE_GAE] 0950 | loss 0.802247 | mse 0.404988 | bce 0.794518\n",
      "[SAGE_GAE] 1000 | loss 0.807942 | mse 0.394918 | bce 0.826047\n",
      "✅ SAGE_GAE (mini-batch): 저장 완료 → sage_gae_mb_anomalies.csv, sage_gae_mb_model.pt\n",
      "✅ 완료: combined_embeddings_64.npy / scaler.joblib / pca64.joblib 저장\n",
      "ℹ️ GAT_GAE → gat_gae_mb_anomalies.csv, SAGE_GAE → sage_gae_mb_anomalies.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "미니배치(Neighbor Sampling)로 학습하는 GAT-GAE & SAGE-GAE\n",
    "입력: Node2Vec(64) + 29속성 결합 → PCA 64 (저장/재사용)\n",
    "손실: 특징 재구성(MSE) + 링크 재구성(BCE, seed 내부 링크)\n",
    "평가도 미니배치로 seed별 x_hat을 붙여 전체 recon MSE 계산\n",
    "\"\"\"\n",
    "\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Node2Vec, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import dump, load\n",
    "\n",
    "# ----------------------------- 설정 ------------------------------\n",
    "NODE_FEAT_CSV = \"node_features.csv\"\n",
    "GRAPH_PKL     = \"G_base_multidigraph.pkl\"\n",
    "\n",
    "# Node2Vec 산출물\n",
    "EMB_NPY  = \"node2vec_embeddings.npy\"\n",
    "EDGE_PT  = \"edge_index.pt\"\n",
    "ADDR_CSV = \"addresses.csv\"\n",
    "N2V_PT   = \"node2vec.pt\"\n",
    "\n",
    "# 결합 임베딩/전처리 저장\n",
    "COMB_EMB_NPY = \"combined_embeddings_64.npy\"\n",
    "SCALER_P     = \"scaler.joblib\"\n",
    "PCA64_P      = \"pca64.joblib\"\n",
    "\n",
    "# 미니배치 하이퍼파라미터\n",
    "BATCH_SIZE   = 1024        # 노드 seed 배치 크기\n",
    "FANOUTS      = [15, 10, 5] # 레이어별 이웃 샘플 크기(=num_neighbors)\n",
    "NUM_WORKERS  = 0           # Windows/Jupyter 안전값\n",
    "PERSISTENT   = False\n",
    "\n",
    "FORCE_RETRAIN_N2V = False\n",
    "LAMBDA_BCE        = 0.5\n",
    "EPOCHS            = 1000\n",
    "DROPOUT           = 0.3\n",
    "LR                = 1e-3\n",
    "WEIGHT_DECAY      = 5e-4\n",
    "SEED              = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ---------------------- 0) 주소/그래프 로드 -----------------------\n",
    "if not os.path.exists(NODE_FEAT_CSV):\n",
    "    raise FileNotFoundError(f\"{NODE_FEAT_CSV} 없음\")\n",
    "if not os.path.exists(GRAPH_PKL):\n",
    "    raise FileNotFoundError(f\"{GRAPH_PKL} 없음\")\n",
    "\n",
    "node_df = pd.read_csv(NODE_FEAT_CSV)\n",
    "addresses_cur = node_df['address'].astype(str).tolist()\n",
    "addr2idx = {a: i for i,a in enumerate(addresses_cur)}\n",
    "\n",
    "with open(GRAPH_PKL, \"rb\") as f:\n",
    "    import networkx as nx\n",
    "    G_nx = pickle.load(f)  # MultiDiGraph\n",
    "\n",
    "edges = []\n",
    "for u, v, _k in G_nx.edges(keys=True):\n",
    "    if u in addr2idx and v in addr2idx:\n",
    "        edges.append([addr2idx[u], addr2idx[v]])\n",
    "edge_index_cpu = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2,E] CPU\n",
    "num_nodes = len(addresses_cur)\n",
    "print(f\"DEVICE: {DEVICE} | nodes: {num_nodes} | edges: {edge_index_cpu.size(1)}\")\n",
    "\n",
    "# (선택) 양방향 추가: 안정성↑\n",
    "# edge_index_cpu = torch.cat([edge_index_cpu, edge_index_cpu.flip(0)], dim=1)\n",
    "\n",
    "# ---------------------- 1) Node2Vec 로드/학습 ----------------------\n",
    "def try_load_saved_n2v():\n",
    "    if not (os.path.exists(EMB_NPY) and os.path.exists(EDGE_PT) and os.path.exists(ADDR_CSV)):\n",
    "        return None\n",
    "    addr_saved = pd.read_csv(ADDR_CSV)['address'].astype(str).tolist()\n",
    "    if len(addr_saved)!=len(addresses_cur) or any(a!=b for a,b in zip(addr_saved, addresses_cur)):\n",
    "        print(\"⚠️ 저장된 addresses와 현재가 불일치 → N2V 재학습\")\n",
    "        return None\n",
    "    x_np = np.load(EMB_NPY)\n",
    "    if x_np.shape!=(len(addresses_cur), 64):\n",
    "        print(\"⚠️ 저장된 임베딩 크기 불일치 → N2V 재학습\")\n",
    "        return None\n",
    "    edge_saved = torch.load(EDGE_PT, map_location=\"cpu\")\n",
    "    if edge_saved.dtype!=torch.long or edge_saved.dim()!=2 or edge_saved.size(0)!=2:\n",
    "        print(\"⚠️ 저장된 edge_index 형식 이상 → N2V 재학습\")\n",
    "        return None\n",
    "    print(\"✅ 저장된 Node2Vec 임베딩/엣지/주소 사용\")\n",
    "    return torch.tensor(x_np, dtype=torch.float32), edge_saved, addr_saved\n",
    "\n",
    "x_n2v_cpu = None\n",
    "if not FORCE_RETRAIN_N2V:\n",
    "    loaded = try_load_saved_n2v()\n",
    "    if loaded:\n",
    "        x_n2v_cpu, edge_index_cpu, addresses = loaded\n",
    "\n",
    "if x_n2v_cpu is None:\n",
    "    print(\"🛠️ Node2Vec를 새로 학습합니다...\")\n",
    "    data_cpu = Data(edge_index=edge_index_cpu, num_nodes=num_nodes)\n",
    "    n2v = Node2Vec(\n",
    "        data_cpu.edge_index, embedding_dim=64,\n",
    "        walk_length=30, context_size=10, walks_per_node=200,\n",
    "        p=1.0, q=1.0, num_negative_samples=1, sparse=True\n",
    "    )\n",
    "    n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=0, persistent_workers=False)\n",
    "    n2v_opt = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "    def train_n2v(epochs=5):\n",
    "        n2v.train()\n",
    "        for ep in range(1, epochs+1):\n",
    "            tot=0.0\n",
    "            for pos_rw, neg_rw in n2v_loader:\n",
    "                n2v_opt.zero_grad()\n",
    "                loss = n2v.loss(pos_rw, neg_rw)\n",
    "                loss.backward(); n2v_opt.step()\n",
    "                tot += loss.item()\n",
    "            print(f\"[Node2Vec] epoch {ep:03d} | loss {tot/len(n2v_loader):.4f}\")\n",
    "    train_n2v(epochs=5)\n",
    "    with torch.no_grad():\n",
    "        x_n2v_cpu = n2v.embedding.weight.clone().detach()   # (N,64)\n",
    "    # 저장\n",
    "    np.save(EMB_NPY, x_n2v_cpu.numpy())\n",
    "    torch.save(edge_index_cpu, EDGE_PT)\n",
    "    pd.Series(addresses_cur, name=\"address\").to_csv(ADDR_CSV, index=False)\n",
    "    try: torch.save(n2v.state_dict(), N2V_PT)\n",
    "    except Exception as e: print(f\"(참고) Node2Vec state 저장 생략: {e}\")\n",
    "    addresses = addresses_cur\n",
    "    print(\"✅ Node2Vec 저장 완료\")\n",
    "\n",
    "# ---------------- 2) 29속성과 결합 → 64차 투영(PCA) ----------------\n",
    "node = pd.read_csv(NODE_FEAT_CSV).set_index(\"address\")\n",
    "feat_cols = [c for c in node.columns]\n",
    "X_attr = node.reindex(addresses)[feat_cols].replace([np.inf,-np.inf], np.nan).fillna(0).astype(float).values  # (N,29)\n",
    "\n",
    "if os.path.exists(SCALER_P) and os.path.exists(PCA64_P):\n",
    "    try:\n",
    "        scaler = load(SCALER_P); pca64 = load(PCA64_P)\n",
    "        print(\"✅ 저장된 Scaler/PCA 로드\")\n",
    "    except Exception:\n",
    "        scaler = StandardScaler().fit(X_attr)\n",
    "        X_concat_fit = np.hstack([x_n2v_cpu.numpy(), scaler.transform(X_attr)])\n",
    "        pca64  = PCA(n_components=64, random_state=SEED).fit(X_concat_fit)\n",
    "        dump(scaler, SCALER_P); dump(pca64, PCA64_P)\n",
    "else:\n",
    "    scaler = StandardScaler().fit(X_attr)\n",
    "    X_concat_fit = np.hstack([x_n2v_cpu.numpy(), scaler.transform(X_attr)])\n",
    "    pca64  = PCA(n_components=64, random_state=SEED).fit(X_concat_fit)\n",
    "    dump(scaler, SCALER_P); dump(pca64, PCA64_P)\n",
    "\n",
    "X_concat = np.hstack([x_n2v_cpu.numpy(), scaler.transform(X_attr)])   # (N,93)\n",
    "X64 = pca64.transform(X_concat).astype(np.float32)                     # (N,64)\n",
    "np.save(COMB_EMB_NPY, X64)\n",
    "print(\"✅ 결합 임베딩 저장:\", COMB_EMB_NPY)\n",
    "\n",
    "x_all = torch.tensor(X64, dtype=torch.float32, device=DEVICE)  # 전체 노드 특성(64)\n",
    "data_full = Data(edge_index=edge_index_cpu, num_nodes=num_nodes)  # 특징은 외부 x_all 사용\n",
    "\n",
    "# ----------------------- 3) 미니배치 로더 --------------------------\n",
    "train_loader = NeighborLoader(\n",
    "    data_full,\n",
    "    input_nodes=torch.arange(num_nodes),      # 전체 노드 대상\n",
    "    num_neighbors=FANOUTS,                    # 레이어별 이웃 수\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=PERSISTENT\n",
    ")\n",
    "eval_loader = NeighborLoader(\n",
    "    data_full,\n",
    "    input_nodes=torch.arange(num_nodes),\n",
    "    num_neighbors=FANOUTS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "# ----------------------- 4) 모델 정의 ------------------------------\n",
    "class GAT_GAE(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.do = dropout\n",
    "        self.g1 = GATConv(in_dim, 32, heads=8, concat=True, dropout=dropout)  # 64 -> 256\n",
    "        self.g2 = GATConv(256, 32, heads=1, concat=True, dropout=dropout)     # 256 -> 32 (z)\n",
    "        self.g3 = GATConv(32, 64, heads=1, concat=True, dropout=dropout)      # 32 -> 64 (x_hat)\n",
    "    def forward(self, x, ei):\n",
    "        x = F.dropout(x, p=self.do, training=self.training); x = F.elu(self.g1(x, ei))\n",
    "        x = F.dropout(x, p=self.do, training=self.training); z = F.elu(self.g2(x, ei))\n",
    "        x_hat = F.dropout(z, p=self.do, training=self.training); x_hat = self.g3(x_hat, ei)\n",
    "        return x_hat, z\n",
    "\n",
    "class SAGE_GAE(nn.Module):\n",
    "    def __init__(self, in_dim=64, dropout=0.3, aggr=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.do = dropout\n",
    "        self.s1 = SAGEConv(in_dim, 256, aggr=aggr)\n",
    "        self.s2 = SAGEConv(256, 32, aggr=aggr)\n",
    "        self.s3 = SAGEConv(32, 64, aggr=aggr)\n",
    "    def forward(self, x, ei):\n",
    "        x = F.dropout(x, p=self.do, training=self.training); x = F.elu(self.s1(x, ei))\n",
    "        z = F.dropout(x, p=self.do, training=self.training); z = F.elu(self.s2(z, ei))\n",
    "        x_hat = F.dropout(z, p=self.do, training=self.training); x_hat = self.s3(x_hat, ei)\n",
    "        return x_hat, z\n",
    "\n",
    "def local_link_bce(z_local, edge_index_local, batch_size):\n",
    "    \"\"\"\n",
    "    z_local: (N_batch_all, d)   # 미니배치 서브그래프의 모든 노드 임베딩\n",
    "    edge_index_local: [2, E_local]  # 로컬 인덱스(0..N_batch_all-1)\n",
    "    batch_size: seed 노드 개수 (0..batch_size-1 가 seed)\n",
    "    -> seed 내부(edge 양 끝이 seed에 모두 속하는) 양성 간선만 사용\n",
    "    \"\"\"\n",
    "    src, dst = edge_index_local\n",
    "    seed_mask = (src < batch_size) & (dst < batch_size)\n",
    "    pos = edge_index_local[:, seed_mask]\n",
    "    if pos.numel() == 0:\n",
    "        # seed 내부 간선이 없으면 seed 범위에서 임의 음성만 사용 (양성 0 → BCE만으론 학습 의미 적음)\n",
    "        # 안전하게 아주 작은 값 반환\n",
    "        return torch.tensor(0.0, device=z_local.device)\n",
    "    # 로컬 seed 서브그래프 기준으로 negative_sampling\n",
    "    num_neg = pos.size(1)  # pos 수만큼\n",
    "    neg = negative_sampling(pos, num_nodes=batch_size, num_neg_samples=num_neg, method='sparse')\n",
    "    # 디코더(점곱)\n",
    "    z_seed = z_local[:batch_size]\n",
    "    def dot_decode(z, e): return (z[e[0]] * z[e[1]]).sum(dim=1)\n",
    "    logits = torch.cat([dot_decode(z_seed, pos), dot_decode(z_seed, neg)], dim=0)\n",
    "    labels = torch.cat([torch.ones(pos.size(1), device=logits.device),\n",
    "                        torch.zeros(neg.size(1), device=logits.device)], dim=0)\n",
    "    return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "# ----------------------- 5) 미니배치 학습 루틴 ----------------------\n",
    "def train_minibatch(model, epochs, name):\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        loss_running = mse_running = bce_running = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            # batch: 로컬 서브그래프\n",
    "            # batch.n_id: 글로벌 노드 인덱스 (길이 = N_batch_all)\n",
    "            # batch.batch_size: seed 노드 개수\n",
    "            n_id = batch.n_id.to(DEVICE)               # 글로벌 → 장치\n",
    "            ei   = batch.edge_index.to(DEVICE)         # 로컬 엣지\n",
    "            x_mb = x_all[n_id]                         # 로컬 노드 특징(순서 = 로컬 인덱스)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            x_hat, z = model(x_mb, ei)\n",
    "\n",
    "            # MSE: seed 노드만\n",
    "            bs = batch.batch_size\n",
    "            mse = F.mse_loss(x_hat[:bs], x_mb[:bs])\n",
    "\n",
    "            # 링크 BCE: seed 내부 간선만\n",
    "            bce = local_link_bce(z, ei, bs)\n",
    "\n",
    "            loss = mse + LAMBDA_BCE * bce\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "            loss_running += float(loss.item())\n",
    "            mse_running  += float(mse.item())\n",
    "            bce_running  += float(bce.item())\n",
    "            steps += 1\n",
    "\n",
    "        if ep == 1 or ep % 50 == 0:\n",
    "            print(f\"[{name}] {ep:04d} | loss {loss_running/steps:.6f} | mse {mse_running/steps:.6f} | bce {bce_running/steps:.6f}\")\n",
    "\n",
    "    # ------------- 평가(미니배치로 전체 seed 재구성 붙이기) -------------\n",
    "    model.eval()\n",
    "    recon_err = np.zeros(num_nodes, dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            n_id = batch.n_id.to(DEVICE)\n",
    "            ei   = batch.edge_index.to(DEVICE)\n",
    "            x_mb = x_all[n_id]\n",
    "\n",
    "            x_hat, _z = model(x_mb, ei)\n",
    "            bs = batch.batch_size\n",
    "            # seed 대응 글로벌 인덱스\n",
    "            seeds_global = n_id[:bs]\n",
    "            # per-node MSE\n",
    "            err = torch.mean((x_hat[:bs] - x_mb[:bs])**2, dim=1).detach().cpu().numpy()\n",
    "            recon_err[seeds_global.cpu().numpy()] = err\n",
    "\n",
    "    mu, sd = recon_err.mean(), recon_err.std(ddof=1) if recon_err.size > 1 else 1e-8\n",
    "    zscore = (recon_err - mu) / (sd if sd > 0 else 1e-8)\n",
    "    cut = np.percentile(zscore, 95.0)\n",
    "    anom = (zscore > cut).astype(int)\n",
    "\n",
    "    out = pd.DataFrame({\"address\": addresses, \"recon_mse\": recon_err, \"z_score\": zscore, \"is_anomaly_top5pct\": anom})\n",
    "    csv_name = f\"{name.lower()}_mb_anomalies.csv\"\n",
    "    pt_name  = f\"{name.lower()}_mb_model.pt\"\n",
    "    out.sort_values(\"z_score\", ascending=False).to_csv(csv_name, index=False, encoding=\"utf-8\")\n",
    "    torch.save(model.state_dict(), pt_name)\n",
    "    print(f\"✅ {name} (mini-batch): 저장 완료 → {csv_name}, {pt_name}\")\n",
    "    return out\n",
    "\n",
    "# -------------------- 6) 두 모델 연속 실행 ------------------------\n",
    "gat_out  = train_minibatch(GAT_GAE(in_dim=64, dropout=DROPOUT),  EPOCHS, \"GAT_GAE\")\n",
    "sage_out = train_minibatch(SAGE_GAE(in_dim=64, dropout=DROPOUT), EPOCHS, \"SAGE_GAE\")\n",
    "\n",
    "print(\"✅ 완료: combined_embeddings_64.npy / scaler.joblib / pca64.joblib 저장\")\n",
    "print(\"ℹ️ GAT_GAE → gat_gae_mb_anomalies.csv, SAGE_GAE → sage_gae_mb_anomalies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1bec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_ae_an = pd.read_csv(\"gat_ae_anomalies.csv\")\n",
    "sage_ae_an = pd.read_csv(\"sage_ae_anomalies.csv\")\n",
    "\n",
    "gat_gae_an = pd.read_csv(\"gat_gae_anomalies.csv\")\n",
    "sage_gae_an = pd.read_csv(\"sage_gae_anomalies.csv\")\n",
    "\n",
    "gat_gae_mb_an = pd.read_csv(\"gat_gae_mb_anomalies.csv\")\n",
    "sage_gae_mb_an = pd.read_csv(\"sage_gae_mb_anomalies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d8524b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>recon_mse</th>\n",
       "      <th>z_score</th>\n",
       "      <th>is_anomaly_top5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0</td>\n",
       "      <td>1.074462</td>\n",
       "      <td>16.639975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x9a9eb7e103230d3baf2bd2ddc7eae69dbb3f77b8</td>\n",
       "      <td>0.979735</td>\n",
       "      <td>15.079760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x167a9333bf582556f35bd4d16a7e80e191aa6476</td>\n",
       "      <td>0.973421</td>\n",
       "      <td>14.975760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xf37b1a35647e4efc1afec5bb870e0bcbf1ac2ffc</td>\n",
       "      <td>0.911353</td>\n",
       "      <td>13.953463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xf204a7552bb25302a70f8695c7d5edbc8e32cb85</td>\n",
       "      <td>0.897239</td>\n",
       "      <td>13.720983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0xb5f756611eddfbd63f4e8d28f2a62a401431c35a</td>\n",
       "      <td>0.871787</td>\n",
       "      <td>13.301768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x11784e0732270b41dd7aba1baa266f076b78f085</td>\n",
       "      <td>0.844250</td>\n",
       "      <td>12.848221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0xaf0ae50cd011e741cdb90f624b5ff0f06fd6ef58</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>12.774575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16</td>\n",
       "      <td>0.829123</td>\n",
       "      <td>12.599068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x19095a519eccd68213b6aa7a80577337d291006e</td>\n",
       "      <td>0.784288</td>\n",
       "      <td>11.860599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      address  recon_mse    z_score  \\\n",
       "0  0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0   1.074462  16.639975   \n",
       "1  0x9a9eb7e103230d3baf2bd2ddc7eae69dbb3f77b8   0.979735  15.079760   \n",
       "2  0x167a9333bf582556f35bd4d16a7e80e191aa6476   0.973421  14.975760   \n",
       "3  0xf37b1a35647e4efc1afec5bb870e0bcbf1ac2ffc   0.911353  13.953463   \n",
       "4  0xf204a7552bb25302a70f8695c7d5edbc8e32cb85   0.897239  13.720983   \n",
       "5  0xb5f756611eddfbd63f4e8d28f2a62a401431c35a   0.871787  13.301768   \n",
       "6  0x11784e0732270b41dd7aba1baa266f076b78f085   0.844250  12.848221   \n",
       "7  0xaf0ae50cd011e741cdb90f624b5ff0f06fd6ef58   0.839779  12.774575   \n",
       "8  0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16   0.829123  12.599068   \n",
       "9  0x19095a519eccd68213b6aa7a80577337d291006e   0.784288  11.860599   \n",
       "\n",
       "   is_anomaly_top5pct  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_ae_an[gat_ae_an['is_anomaly_top5pct'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417be66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>recon_mse</th>\n",
       "      <th>z_score</th>\n",
       "      <th>is_anomaly_top5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x9a9eb7e103230d3baf2bd2ddc7eae69dbb3f77b8</td>\n",
       "      <td>0.838493</td>\n",
       "      <td>14.989171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x167a9333bf582556f35bd4d16a7e80e191aa6476</td>\n",
       "      <td>0.800249</td>\n",
       "      <td>14.254773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0</td>\n",
       "      <td>0.768789</td>\n",
       "      <td>13.650672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xf37b1a35647e4efc1afec5bb870e0bcbf1ac2ffc</td>\n",
       "      <td>0.764231</td>\n",
       "      <td>13.563149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xf204a7552bb25302a70f8695c7d5edbc8e32cb85</td>\n",
       "      <td>0.760840</td>\n",
       "      <td>13.498028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0xb5f756611eddfbd63f4e8d28f2a62a401431c35a</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>12.877007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16</td>\n",
       "      <td>0.727814</td>\n",
       "      <td>12.863837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x11784e0732270b41dd7aba1baa266f076b78f085</td>\n",
       "      <td>0.703027</td>\n",
       "      <td>12.387865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xaf0ae50cd011e741cdb90f624b5ff0f06fd6ef58</td>\n",
       "      <td>0.683921</td>\n",
       "      <td>12.020988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x19095a519eccd68213b6aa7a80577337d291006e</td>\n",
       "      <td>0.681271</td>\n",
       "      <td>11.970102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      address  recon_mse    z_score  \\\n",
       "0  0x9a9eb7e103230d3baf2bd2ddc7eae69dbb3f77b8   0.838493  14.989171   \n",
       "1  0x167a9333bf582556f35bd4d16a7e80e191aa6476   0.800249  14.254773   \n",
       "2  0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0   0.768789  13.650672   \n",
       "3  0xf37b1a35647e4efc1afec5bb870e0bcbf1ac2ffc   0.764231  13.563149   \n",
       "4  0xf204a7552bb25302a70f8695c7d5edbc8e32cb85   0.760840  13.498028   \n",
       "5  0xb5f756611eddfbd63f4e8d28f2a62a401431c35a   0.728500  12.877007   \n",
       "6  0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16   0.727814  12.863837   \n",
       "7  0x11784e0732270b41dd7aba1baa266f076b78f085   0.703027  12.387865   \n",
       "8  0xaf0ae50cd011e741cdb90f624b5ff0f06fd6ef58   0.683921  12.020988   \n",
       "9  0x19095a519eccd68213b6aa7a80577337d291006e   0.681271  11.970102   \n",
       "\n",
       "   is_anomaly_top5pct  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sage_ae_an[sage_ae_an['is_anomaly_top5pct'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27fb1aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>recon_mse</th>\n",
       "      <th>z_score</th>\n",
       "      <th>is_anomaly_top5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x167a9333bf582556f35bd4d16a7e80e191aa6476</td>\n",
       "      <td>982.400940</td>\n",
       "      <td>73.656010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece</td>\n",
       "      <td>295.798220</td>\n",
       "      <td>22.151089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1f69b6147203344049ea381f5dd2008714caedda</td>\n",
       "      <td>280.451140</td>\n",
       "      <td>20.999840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>275.396060</td>\n",
       "      <td>20.620638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xd4b394c60bb55f80df30dac87b6f92be34739332</td>\n",
       "      <td>254.439870</td>\n",
       "      <td>19.048626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "      <td>232.739840</td>\n",
       "      <td>17.420818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0</td>\n",
       "      <td>205.130690</td>\n",
       "      <td>15.349741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0xa5025faba6e70b84f74e9b1113e5f7f4e7f4859f</td>\n",
       "      <td>123.233376</td>\n",
       "      <td>9.206282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37</td>\n",
       "      <td>110.310020</td>\n",
       "      <td>8.236848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16</td>\n",
       "      <td>78.658590</td>\n",
       "      <td>5.862543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      address   recon_mse    z_score  \\\n",
       "0  0x167a9333bf582556f35bd4d16a7e80e191aa6476  982.400940  73.656010   \n",
       "1  0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece  295.798220  22.151089   \n",
       "2  0x1f69b6147203344049ea381f5dd2008714caedda  280.451140  20.999840   \n",
       "3  0xd28493e737fbcc957f3716143ed6e40f40357b51  275.396060  20.620638   \n",
       "4  0xd4b394c60bb55f80df30dac87b6f92be34739332  254.439870  19.048626   \n",
       "5  0x0000000000000000000000000000000000000000  232.739840  17.420818   \n",
       "6  0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0  205.130690  15.349741   \n",
       "7  0xa5025faba6e70b84f74e9b1113e5f7f4e7f4859f  123.233376   9.206282   \n",
       "8  0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37  110.310020   8.236848   \n",
       "9  0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16   78.658590   5.862543   \n",
       "\n",
       "   is_anomaly_top5pct  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_gae_an[gat_gae_an['is_anomaly_top5pct'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e6ebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>recon_mse</th>\n",
       "      <th>z_score</th>\n",
       "      <th>is_anomaly_top5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x167a9333bf582556f35bd4d16a7e80e191aa6476</td>\n",
       "      <td>980.456400</td>\n",
       "      <td>73.610580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece</td>\n",
       "      <td>293.959170</td>\n",
       "      <td>22.043434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1f69b6147203344049ea381f5dd2008714caedda</td>\n",
       "      <td>279.166100</td>\n",
       "      <td>20.932234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>273.299320</td>\n",
       "      <td>20.491543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xd4b394c60bb55f80df30dac87b6f92be34739332</td>\n",
       "      <td>250.081900</td>\n",
       "      <td>18.747536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "      <td>246.659940</td>\n",
       "      <td>18.490492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0</td>\n",
       "      <td>204.375640</td>\n",
       "      <td>15.314251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0xa5025faba6e70b84f74e9b1113e5f7f4e7f4859f</td>\n",
       "      <td>120.477280</td>\n",
       "      <td>9.012116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37</td>\n",
       "      <td>110.667700</td>\n",
       "      <td>8.275256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16</td>\n",
       "      <td>77.889534</td>\n",
       "      <td>5.813081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      address   recon_mse    z_score  \\\n",
       "0  0x167a9333bf582556f35bd4d16a7e80e191aa6476  980.456400  73.610580   \n",
       "1  0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece  293.959170  22.043434   \n",
       "2  0x1f69b6147203344049ea381f5dd2008714caedda  279.166100  20.932234   \n",
       "3  0xd28493e737fbcc957f3716143ed6e40f40357b51  273.299320  20.491543   \n",
       "4  0xd4b394c60bb55f80df30dac87b6f92be34739332  250.081900  18.747536   \n",
       "5  0x0000000000000000000000000000000000000000  246.659940  18.490492   \n",
       "6  0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0  204.375640  15.314251   \n",
       "7  0xa5025faba6e70b84f74e9b1113e5f7f4e7f4859f  120.477280   9.012116   \n",
       "8  0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37  110.667700   8.275256   \n",
       "9  0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16   77.889534   5.813081   \n",
       "\n",
       "   is_anomaly_top5pct  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sage_gae_an[sage_gae_an['is_anomaly_top5pct'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc656577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>recon_mse</th>\n",
       "      <th>z_score</th>\n",
       "      <th>is_anomaly_top5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x167a9333bf582556f35bd4d16a7e80e191aa6476</td>\n",
       "      <td>982.01010</td>\n",
       "      <td>74.976320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece</td>\n",
       "      <td>294.19693</td>\n",
       "      <td>22.437508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1f69b6147203344049ea381f5dd2008714caedda</td>\n",
       "      <td>279.11370</td>\n",
       "      <td>21.285372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xd4b394c60bb55f80df30dac87b6f92be34739332</td>\n",
       "      <td>254.99422</td>\n",
       "      <td>19.442997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>213.19151</td>\n",
       "      <td>16.249886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0</td>\n",
       "      <td>204.81764</td>\n",
       "      <td>15.610245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "      <td>191.34544</td>\n",
       "      <td>14.581166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0xa5025faba6e70b84f74e9b1113e5f7f4e7f4859f</td>\n",
       "      <td>121.95533</td>\n",
       "      <td>9.280783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37</td>\n",
       "      <td>111.11345</td>\n",
       "      <td>8.452622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16</td>\n",
       "      <td>78.07902</td>\n",
       "      <td>5.929277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      address  recon_mse    z_score  \\\n",
       "0  0x167a9333bf582556f35bd4d16a7e80e191aa6476  982.01010  74.976320   \n",
       "1  0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece  294.19693  22.437508   \n",
       "2  0x1f69b6147203344049ea381f5dd2008714caedda  279.11370  21.285372   \n",
       "3  0xd4b394c60bb55f80df30dac87b6f92be34739332  254.99422  19.442997   \n",
       "4  0xd28493e737fbcc957f3716143ed6e40f40357b51  213.19151  16.249886   \n",
       "5  0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0  204.81764  15.610245   \n",
       "6  0x0000000000000000000000000000000000000000  191.34544  14.581166   \n",
       "7  0xa5025faba6e70b84f74e9b1113e5f7f4e7f4859f  121.95533   9.280783   \n",
       "8  0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37  111.11345   8.452622   \n",
       "9  0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16   78.07902   5.929277   \n",
       "\n",
       "   is_anomaly_top5pct  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_gae_mb_an[gat_gae_mb_an['is_anomaly_top5pct'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e3c009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>recon_mse</th>\n",
       "      <th>z_score</th>\n",
       "      <th>is_anomaly_top5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x167a9333bf582556f35bd4d16a7e80e191aa6476</td>\n",
       "      <td>970.829200</td>\n",
       "      <td>79.920140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1f69b6147203344049ea381f5dd2008714caedda</td>\n",
       "      <td>278.117030</td>\n",
       "      <td>22.873000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece</td>\n",
       "      <td>271.768980</td>\n",
       "      <td>22.350216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0</td>\n",
       "      <td>183.511540</td>\n",
       "      <td>15.081924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xd28493e737fbcc957f3716143ed6e40f40357b51</td>\n",
       "      <td>119.247780</td>\n",
       "      <td>9.789589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37</td>\n",
       "      <td>91.081800</td>\n",
       "      <td>7.470028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "      <td>81.365660</td>\n",
       "      <td>6.669871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16</td>\n",
       "      <td>74.387160</td>\n",
       "      <td>6.095169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xd4b394c60bb55f80df30dac87b6f92be34739332</td>\n",
       "      <td>64.854290</td>\n",
       "      <td>5.310105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0xf204a7552bb25302a70f8695c7d5edbc8e32cb85</td>\n",
       "      <td>58.322456</td>\n",
       "      <td>4.772187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      address   recon_mse    z_score  \\\n",
       "0  0x167a9333bf582556f35bd4d16a7e80e191aa6476  970.829200  79.920140   \n",
       "1  0x1f69b6147203344049ea381f5dd2008714caedda  278.117030  22.873000   \n",
       "2  0x0ce15800ebc76a1034d320ad2abcd0e77ba52ece  271.768980  22.350216   \n",
       "3  0x1938a448d105d26c40a52a1bfe99b8ca7a745ad0  183.511540  15.081924   \n",
       "4  0xd28493e737fbcc957f3716143ed6e40f40357b51  119.247780   9.789589   \n",
       "5  0xfea2c6d96f0bd4cd4d638bcefa7968146c74df37   91.081800   7.470028   \n",
       "6  0x0000000000000000000000000000000000000000   81.365660   6.669871   \n",
       "7  0x1d5a1eaf90218e91f2bb32e42b0b02ff39827d16   74.387160   6.095169   \n",
       "8  0xd4b394c60bb55f80df30dac87b6f92be34739332   64.854290   5.310105   \n",
       "9  0xf204a7552bb25302a70f8695c7d5edbc8e32cb85   58.322456   4.772187   \n",
       "\n",
       "   is_anomaly_top5pct  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sage_gae_mb_an[sage_gae_mb_an['is_anomaly_top5pct'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_ae_anomalies, sage_ae_anomalies, gat_gae_anomalies, sage_gae_anomalies, gat_gae_mb_anomalies, sage_gae_mb_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7757e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 비교 결과: gat_ae_anomalies.csv  vs  sage_ae_anomalies.csv ===\n",
      "A(=왼쪽) 이상치 수: 398\n",
      "B(=오른쪽) 이상치 수: 398\n",
      "교집합: 385 / 합집합: 411\n",
      "Jaccard: 0.9367\n",
      "Overlap Coefficient: 0.9673  (|A∩B| / min(|A|,|B|))\n",
      "Precision(A→B): 0.9673   Recall(A→B): 0.9673   F1: 0.9673\n",
      "파일 저장 → common_gat_ae_anomalies__sage_ae_anomalies.csv, only_gat_ae_anomalies.csv, only_sage_ae_anomalies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================\n",
    "# 파일명만 바꿔서 실행하세요 (예시)\n",
    "file_a = \"gat_ae_anomalies\"   # 예: \"gat_ae_an\", \"sage_gae_an\", ...\n",
    "file_b = \"sage_ae_anomalies\"\n",
    "# ============================================\n",
    "\n",
    "def ensure_csv(path_like: str) -> str:\n",
    "    return path_like if str(path_like).lower().endswith(\".csv\") else str(path_like) + \".csv\"\n",
    "\n",
    "def load_anomaly_addresses(csv_path: str) -> pd.Series:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # 컬럼 체크\n",
    "    required = {\"address\", \"is_anomaly_top5pct\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        missing = required - set(df.columns)\n",
    "        raise ValueError(f\"{csv_path}: 필요한 컬럼이 없습니다 → {missing}\")\n",
    "    # 필터링: is_anomaly_top5pct == 1\n",
    "    s = df.loc[(df[\"is_anomaly_top5pct\"].astype(float) == 1), \"address\"]\n",
    "    # 주소 정규화(소문자/공백 제거)\n",
    "    s = s.astype(str).str.strip().str.lower()\n",
    "    return s.dropna()\n",
    "\n",
    "def compare_two(csv_a: str, csv_b: str):\n",
    "    csv_a = ensure_csv(csv_a)\n",
    "    csv_b = ensure_csv(csv_b)\n",
    "\n",
    "    a = load_anomaly_addresses(csv_a)\n",
    "    b = load_anomaly_addresses(csv_b)\n",
    "\n",
    "    A = set(a.unique())\n",
    "    B = set(b.unique())\n",
    "    inter = A & B\n",
    "    union = A | B\n",
    "\n",
    "    # 지표들\n",
    "    nA, nB, nI, nU = len(A), len(B), len(inter), len(union)\n",
    "    jaccard = nI / nU if nU else 0.0\n",
    "    overlap_coeff = nI / min(nA, nB) if min(nA, nB) else 0.0\n",
    "    prec_A_to_B = nI / nA if nA else 0.0\n",
    "    rec_A_to_B  = nI / nB if nB else 0.0\n",
    "    f1 = (2*prec_A_to_B*rec_A_to_B)/(prec_A_to_B+rec_A_to_B) if (prec_A_to_B+rec_A_to_B)>0 else 0.0\n",
    "\n",
    "    print(f\"=== 비교 결과: {Path(csv_a).name}  vs  {Path(csv_b).name} ===\")\n",
    "    print(f\"A(=왼쪽) 이상치 수: {nA}\")\n",
    "    print(f\"B(=오른쪽) 이상치 수: {nB}\")\n",
    "    print(f\"교집합: {nI} / 합집합: {nU}\")\n",
    "    print(f\"Jaccard: {jaccard:.4f}\")\n",
    "    print(f\"Overlap Coefficient: {overlap_coeff:.4f}  (|A∩B| / min(|A|,|B|))\")\n",
    "    print(f\"Precision(A→B): {prec_A_to_B:.4f}   Recall(A→B): {rec_A_to_B:.4f}   F1: {f1:.4f}\")\n",
    "\n",
    "    # 결과를 파일로도 저장(원하면 주석 해제)\n",
    "    stemA, stemB = Path(csv_a).stem, Path(csv_b).stem\n",
    "    pd.Series(sorted(inter), name=\"address\").to_csv(f\"common_{stemA}__{stemB}.csv\", index=False)\n",
    "    pd.Series(sorted(A - B), name=\"address\").to_csv(f\"only_{stemA}.csv\", index=False)\n",
    "    pd.Series(sorted(B - A), name=\"address\").to_csv(f\"only_{stemB}.csv\", index=False)\n",
    "    print(f\"파일 저장 → common_{stemA}__{stemB}.csv, only_{stemA}.csv, only_{stemB}.csv\")\n",
    "\n",
    "# 실행\n",
    "compare_two(file_a, file_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
